# 机器学习

## 01. 机器学习基本概念概述

### 1.1 机器学习定义

**机器学习（Machine Learning）**：  
本质上是让计算机在已有数据中学习规律，并根据这些规律对未来进行预测。

常见机器学习算法包括：

- **线性回归**
- **逻辑回归**
- **聚类算法**（K-Means）
- **决策树**
- **朴素贝叶斯**
- **深度学习算法**
  - CNN（卷积神经网络）
  - RNN（循环神经网络）
  - LSTM（长短期记忆网络）
    ![1763535975723](image/machine-learning/1763535975723.png)

---

### 1.2 机器学习的发展历史

![1763535918600](image/machine-learning/1763535918600.png)

- **20 世纪 50 年代**：人工智能概念提出，目标是让计算机模拟人类智能。
- **20 世纪 80 年代**：神经网络（BP）开始兴起，尝试模拟人脑神经元结构处理信息。
- 随着时间发展，支持向量机、朴素贝叶斯等算法出现，机器学习由“知识驱动”转向“数据驱动”。
- **2012 年**：算力提升 + 大规模数据 → 深度学习复兴，成为最热门研究方向，推动工业应用爆发。

---

### 1.3 机器学习分类

机器学习根据数据标注情况与学习模式，可分为：

- **监督学习**
- **半监督学习**
- **强化学习**

---

#### 1.3.1 监督学习（Supervised Learning）

##### 1.3.1.1 定义

**基本解释：** 给模型大量已有的**标记数据**（例如：图片 + 标签、人名 + 身份）让它学会从输入推断正确输出，学习好模型后，后用训练好的模型去预测新的未知数据。
**通俗解释：**
想象你在教一个小孩区分“猫”和“狗”。

你给他一堆已经**标好名字的照片**：

- 这张是 **猫**
- 这张是 **狗**
- 这张也是 **猫**
- 这张也是 **狗**

这里需要注意两点：

- **这些照片就是数据集（dataset）**
- **每张照片上写的“猫/狗”就是标签（label）**

小孩一开始不会分，但不断看到“图片 + 正确答案（标签）”后，他开始总结规律：

- 猫的耳朵 **更尖**
- 狗的鼻子 **更大**
- 狗的身体 **更壮**
- 猫的眼睛 **更圆**

当他掌握了这些规律后，你给他一张从未见过的新照片，他已经能自信判断：

> “这应该是猫。”

---

**这就是监督学习的核心流程：**

- 给模型大量 **带标签的数据集** → 模型从中学习规律
- 规律学会后 → 用来 **预测新的未知数据**
- 整个过程就像“老师带着学生做题，让学生从答案中归纳知识”

唯一的区别是：

- **小孩靠大脑学习规律**
- **模型靠数学和算法学习规律**

---

**这就是监督学习的本质：**

- 给模型大量**带答案的数据** → 模型从中学习规律
- 规律学会后 → 用来**预测新的未知数据**
- 整个过程就像“老师带着学生做题”

**唯一的区别：**

- **小孩用的是大脑**
- **模型用的是数学与算法**
  ![1763535842454](image/machine-learning/1763535842454.png)

##### 1.3.1.2 常见算法

1. **线性回归**：通过找到最佳拟合线预测连续值。
2. **逻辑回归**：用于二分类（如 0/1）的监督学习算法。
3. **决策树**：通过树状结构对数据进行分类或回归。

##### 1.3.1.3 常见应用场景

- **分类问题**：垃圾邮件识别、人脸识别
- **回归问题**：股票价格预测、天气预测

---

#### 1.3.2 无监督学习(UnSupervised Learning)

##### 1.3.2.1 定义

**无监督学习**通过分析输入数据的特点和结构，自动地找出数据中的模式和规律不需要人**工标注和干预**
**通俗解释：**
无监督学习好比把一群“没有名字、没有说明书”的东西丢给一个聪明的系统，它不会问你：“这是什么？”  
它会自己观察、自己思考，从数据的形状、分布、相似度里找到规律。

比如：

- 你不给任何标签，把上百张人的照片丢进去
- 模型会自动发现：
  - 有些脸更像一组（可能是男性）
  - 有些脸更像另一组（可能是女性）
  - 还有一些人有眼镜，它也能自动分出来

在整个过程中，没有人告诉它正确答案，也没有人为干预。  
它就是根据**数据本身的结构和特征**，自动把“相似的放一起，不相似的分开”。

---

总结一句话：

> **无监督学习让模型自己在一堆没有标签的数据里找规律，像是在黑暗里摸索，但却能自然形成分类和结构。**

##### 1.3.2.2 常见算法

- 1.**_K-means：_** 用于聚类分析。
- 2.**_DBSCAN：_** 基于密度的算法，发现任意形状的聚类。
- 3.**_层次聚类：_** 基于距离的算法，将数据点按照距离远近进行聚类。

##### 1.3.2.3 应用场景

- 1.**聚类：** 将数据集划分为多个组。
- 2.**降维：** 将高位数据降维，更容易理解和可视化数据。
- 3.**关联规则学习：** 超市购物篮分析中，发现哪些商品经常一起被购买
  ![1763524708476](image/machine-learning/1763524708476.png)

#### 1.3.3 半监督学习(semi-supervised learning)

##### 1.3.3.1 定义

**基本解释：** **半监督学习** 利用标记和未标记的数据来进行训练和预测。

**半监督学习的通俗解释：**

半监督学习就像教一个学生做题，但你手里的资源有限：

- 你只有**少量带答案的题目**（标记数据）
- 还堆着**大量只有题目没有答案的练习册**（未标记数据）

学生会这样学习：

1. 先用“带答案的题”学会基本规律
2. 再把这些规律用到“没答案的题”里，通过反复推断和比较，让自己的理解更深
3. 最终不仅能把带答案的题学会，还能靠自己判断其他新题

所以半监督学习的核心就在于：

> **少量标注指导 + 大量未标注辅助，让模型学得更快、更准，同时减少人工标注成本。**

##### 1.3.3.2 常见算法

- 1.**标签传播：** 通过迭代地传播标签，使得每个样本的标签都尽可能地一致。
- 2.**学习算法：** 通过学习算法可以训练出更好的模型，提高分类准确率。

##### 1.3.3.3 应用场景

- 1.**分类问题：** 垃圾邮件识别、人脸识别等。
- 2.**聚类问题：** 市场细分、社交网络分析等。
  ![1763533320044](image/machine-learning/1763533320044.png)

#### 1.3.4 强化学习(reinforcement learning)

##### 1.3.4.1 定义

**强化学习**通过试错的方式让机器学习如何做出最优决策，最重点的就是智能体和现实环境的交互

**通俗解释：**

强化学习就像训练一只“小聪明的宠物”做任务。

你不会提前告诉它怎么做，也不给它现成的答案，它只能靠**不断尝试、不断犯错、不断总结**来找到最好的做法。

整个过程包含两样东西：

- **智能体（Agent）**：像宠物一样“执行动作”的角色
- **环境（Environment）**：智能体行动所处的世界，会给它奖励或惩罚

举个特别好懂的例子：

你在教小狗钻火圈。

- 小狗试着跳过去，摔下来 → **环境给惩罚**
- 小狗试出正确的跳法，成功穿过去 → **环境给奖励**
- 小狗会把“奖励最多的行为”记下来，下次更容易成功

于是，小狗通过无数次**试错 + 奖励反馈**，最终学会最佳动作。

强化学习的核心就是：

> **让智能体与环境不断互动，通过奖励和惩罚，引导它学会最优决策。**

##### 1.3.4.2 常见算法

- **Q-Learning：** 构建 Q 表来对环境进行建模实现决策。
- **Deep Q Network (DQN)：** 结合深度学习通过训练神经网络来逼近 Q 函数，实现更高效的学习。
- **Policy Gradient Methods：** 优化策略寻找最优解。

### 1.4.应用场景

![1763534576345](image/machine-learning/1763534576345.png)

### 1.5.机器学习发展概述

![1763534625103](image/machine-learning/1763534625103.png)

## 02. 机器学习相关算法

### 2.1 监督学习中的 KNN 算法

**算法概述：**
KNN 算法概念
**K 最近邻(K-Nearest Neighbor,KNN)分类算**法是数据挖掘分类技术中最简单的方法之一，
是著名的模式识别统计学方法，在机器学习分类算法中占有相当大的地位。
它是一个理论上比较成熟的方法。既是最简单的机器学习算法之一，
也是**基于实例**的学习方法中最基本的，又是最好的文本分类算法之一。

- **什么是基于实例学习：**
  **基于实例”（Instance-Based）**指的是：  
   模型**不真正建立复杂的数学公式或函数**，而是把训练数据当成“记忆的实例”保存下来，当有新数据来时，通过比较相似程度来做判断。

  | 类型                           | 思路                                    | 举例                       |
  | ------------------------------ | --------------------------------------- | -------------------------- |
  | **基于实例（Instance-Based）** | 保存训练样本，新样本靠相似度分类        | KNN                        |
  | **基于模型（Model-Based）**    | 从数据中训练出模型/方程，然后用模型预测 | 逻辑回归、决策树、神经网络 |

  **基于模型**：我总结规律，靠规律判断  
  **基于实例**：我不总结，只靠“像不像”判断
  **基于实例 = 靠存例子 + 比距离做判断，而不是构建模型。**

#### 2.1.1 算法介绍

> 该算法就是根据设定好的标签和分类好的数据，画出这些分类好数据的数据边界，再往里放入数据时，该算法就会根据之前设计好的边界分类你重新加入的数据。
> 该算法主是监督学习算法，所以要先预设好带有数据标签的数据集，
> 交叉验证方法主要增强鲁棒性

##### 2.1.1.1 定义

KNN(K-Nearest Neighbor) **k 个最近的邻居**，即每个样本都可以用它最接近的 k 个邻居来代表,KNN 算法属于监督学习方式的分类算法，通过测量不同数据点之间的**距离**进行**分类**或**回归分析**。

- **什么是回归分析：**
  回归分析是一种根据“已有的数值数据”来**预测一个连续数值**的方法。

  > **回归 = 预测一个具体的数字，而不是判断类别。** > **回归不是问：“它属于哪一类？”  
  > 回归是在问：“它到底是多少？”**

  - **最好理解的例子：预测房价**
    你给模型大量**带标签的数据**：

    > 房子面积：80㎡ → 价格 82 万
    > 房子面积：100㎡ → 价格 105 万
    > 房子面积：130㎡ → 价格 140 万
    > **模型从中学会：** **面积越大 → 房价越高 > 之后你给它一个新的数据：** > 120㎡ 的房子**模型不告诉你这是 A 类或 B 类房子**，而是**直接回答**：大概值 **128 万**这就是回归分析。

    | 任务     | 回答的结果       | 例子             |
    | -------- | ---------------- | ---------------- |
    | **分类** | 哪一类？         | “这是狗还是猫？” |
    | **回归** | 具体数值是多少？ | “这房子多少钱？” |

##### 2.1.1.2 原理

“近朱者赤” **基于实例 (instance-based learning)** 的学习,属于 **懒惰学习(Lazy learning)**,即 KNN 没有显示的学习过程，也就是说没有训练阶段（仅仅是把样本保存起来，训练时间开销为零）它是通过测量不同数据点的之间的距离进行**分类**或者**回归**。

##### 2.1.1.3 特点

- KNN 算法简单易懂，易于实现
- **无需训练阶段，直接进行分类或者回归**
- **适用于多分类问题**
- **对数据集的大小和维度不敏感**

#### 2.1.2 KNN 算法三要素

##### 概述

- **1.K 值选择**
  “要参考的最近邻居数量”。它决定了模型是在“听少数人的意见”，还是“听多数人的意见”。
- **2.距离选择**
  KNN 的核心思想是：“近的相似，远的不同”。所以“近”必须有一个衡量方式，这就是**距离度量：**

  - **欧氏距离（Euclidean Distance）**

    - 最常见，用于空间直线距离
    - 类似地图中两点之间的直线

  - **曼哈顿距离（Manhattan Distance）**

    - 用于具有网格结构的数据
    - 走“横平竖直”的距离更合适

  - **切比雪夫距离（Chebyshev Distance）**

    - 适合棋盘、像国际象棋国王移动那样的场景

  - **闵可夫斯基距离（Minkowski Distance）**
    - 欧氏 + 曼哈顿 的更一般版本
    - 距离度量更灵活

- **3.分类规则选择**
  KNN 找到 K 个邻居之后，需要确定最终类别。常见**决策方式**有两种：

  - **多数投票（Majority Voting）**

    - 哪个类别出现次数最多，就选哪个
    - 应用于分类任务（Classification）

  - **距离加权投票（Weighted Voting）**
    - 最近的邻居权重更大
    - 距离越近 → 权重越高
    - 可以更好地处理“局部密度不均匀”的场景

##### 2.1.2.1 K 值选择

算法中的 K 在 KNN 中，称为**超参数(Hyper parameter)(超参数就是需要你手动设定的参数)**，需要人为选择不同的 K 值，这个参数是需要人为选择的。
**K 值选择存在的问题：**
**K 值过小：**

- 优点：复杂的数据集，K 值较小可能会提供更详细的决策边界，因为模型更加灵活。
- 缺点：容易受到局部结构的影响，模型受噪声和异常值的影响更大。
  选择较小的 K 值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练 实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K 值的减小就意味着整体模型变得 复杂，容易发生过拟合；

**k 值过大：**

- 优点：考虑了更多的全局信息，对于平滑的数据集，较大的 K 值可以提供更稳定的决策边界。
- 缺点：对于复杂的数据集，较大的 K 值可能会导致模型过于简单，无法准确捕获数据的局部特征。

选择较大的 K 值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且 **K 值的增大就意着体的模型变得简单。**
**极端情况**，K=N（N 为训练样本个数），则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。
**如何选择最优的 K 值？**
在实际应用中，**K 值一般取一个比较适中的数值**，例如采用交叉验证法（简单来说，就是把训练数据在分成两组:训练集验证集）来选择最优的 K 值。

##### 2.1.2.2 距离选择

**k 近邻法(K-Nearest Neighbor,KNN)**：计算新的点(测试点)到每一个已知点(标签点)的距离，并比对距离,使用不同的距离公式会得到不同的分类效果。后面会介绍一下常用的距离计算方法。

##### 2.1.2.3 分类规则选择

- **分类问题：** 对新的实例，根据与之相邻的 k 个训练实例的类别，通过多数表决法或者加权多数表决法等方式进行预测
- **回归问题：** 对新的实例，根据与之相邻的 K 个训练实例的标签，通过均值计算进行预测。

#### 2.1.3KNN 算法步骤

**输入：** 训练数据集 T={(x1,y1),(x2,y2)...(xn,yn)},x1 为实例的特征向量，yi={c1,c2,c3...ck}为实例类别。
**输出：** 测试实例 x 所属的类别 y。
**步骤：**

- (1)选择参数 **K**
- (2)计算未知实例与所有已知实例的距离(可选择多种计算**距离**的方式)
- (3)选择最近 K 个已知实例
- (4)根据少数服从多数的**投票法则(Majority-voting)**,让未知实例归类为 K 个最近邻样本中最多数的类别。

#### 2.1.4 KNN 算法思想

K 近邻算法，假定给定一个训练数据集，其中实例标签已定，当**输入新的实例**时，可以根据其**最近的 k 个训练实例的标签**，**预测新实例对应的标注信息(标签属于哪一类)**
图中绿色的点就是我们要预测的那个点，假设 K=3。那么 KNN 算法就会找到与它距离最近的三个点（这里用圆圈把它圈起来了），看看哪种类别多一些，比如这个例子中是蓝色三角形多一些，新来的绿色点就归类到蓝三角了。
![1763602926013](image/machine-learning/1763602926013.png)
![1763602919015](image/machine-learning/1763602919015.png)
**决策边界可视化**
![1763602967054](image/machine-learning/1763602967054.png)

#### 2.1.5 决策边界可视化代码实现

```python
# 导入库
# 从sklearn 导入分类的库，KNeighborsClassifier 是 KNN 算法的核心分类器
from sklearn.neighbors import KNeighborsClassifier

# 导入numpy，numpy 是用于数值计算的库，主要用于处理数组
import numpy as np

# 导入画图包，matplotlib 用于数据可视化
import matplotlib.pyplot as plt

# 目前使用课件上的数据集
# 定义三个点集合，代表不同类别的数据点，分别有两个特征（例如：坐标位置）
point1 = [
    [7.7, 6.1],  # 类别 0 的点
    [3.1, 5.9],
    [8.6, 8.8],
    [9.5, 7.3],
    [3.9, 7.4],
    [5.0, 5.3],
    [1.0, 7.3],
]
point2 = [
    [0.2, 2.2],  # 类别 1 的点
    [4.5, 4.1],
    [0.5, 1.1],
    [2.7, 3.0],
    [4.7, 0.2],
    [2.9, 3.3],
    [7.3, 7.9],
]
point3 = [
    [9.2, 0.7],  # 类别 2 的点
    [9.2, 2.1],
    [7.3, 4.5],
    [8.9, 2.9],
    [9.5, 3.7],
    [7.7, 3.7],
    [9.4, 2.4],
]

# 将数据集连接起来，将三个点集合合并成一个大的数据集
# np.concatenate: 用于连接多个数组
# axis=0 表示按行进行拼接
point_concat = np.concatenate((point1, point2, point3), axis=0)

# 设置标签，将每个数据点与其对应的类别标签进行配对
# np.zeros(len(point1)) 给 point1 的所有点分配标签 0
# np.ones(len(point2)) 给 point2 的所有点分配标签 1
# np.ones(len(point3)) + 1 给 point3 的所有点分配标签 2
point_concat_label = np.concatenate(
    (np.zeros(len(point1)), np.ones(len(point2)), np.ones(len(point3)) + 1),
    axis=0,
)

# 2. 构建KNN算法，实例化KNN算法并进行训练
# 2.1 第一步实例化KNN算法，指定邻居数量、距离度量方式等参数
n_neighbors = 5  # 确定K值（即邻居数），这里设定为5

# 使用 KNeighborsClassifier 实例化 KNN 算法模型
# n_neighbors: 选择的邻居数量，指定 KNN 算法考虑的邻居数目
# algorithm: 'brute' 表示使用暴力计算方法，即计算每个点与所有点的距离
# p: 距离度量的参数，p=2 表示使用欧几里得距离
knn = KNeighborsClassifier(
    n_neighbors=n_neighbors,  # 设置 K 值为 5
    algorithm="brute",  # 使用暴力算法来计算距离
    p=2,  # 使用欧几里得距离（p=2）
)

# 训练 KNN 模型
# knn.fit() 函数会根据训练数据（point_concat）和标签（point_concat_label）来学习
# 该函数将模型拟合到数据上，学习数据的特征与标签之间的关系
knn.fit(point_concat, point_concat_label)

# 3. 实现KNN决策边界的可视化
# 通过预测坐标网格上所有点的类别来绘制决策边界
# 获得预测点数据，使用坐标点网格来当作预测数据点
# 3.1 设定未知点，生成一个坐标点网格，表示我们希望预测的点位置
x1 = np.linspace(0, 10, 100)  # 生成从0到10的100个点，作为 x 轴的坐标
# np.linspace: 生成指定范围内的等间距数值
# 第一个参数是数据的起始值，第二个参数是结束值，第三个是生成数值的个数
y1 = np.linspace(0, 10, 100)  # 生成从0到10的100个点，作为 y 轴的坐标

# 生成坐标点网格，x_axis 和 y_axis 是二维矩阵
# meshgrid 用于生成网格坐标点，用于在平面上覆盖坐标点
x_axis, y_axis = np.meshgrid(x1, y1)

# 输出网格形状（这是一个二维的网格，用来覆盖平面）
# 网格的形状（每个轴的维度）对于决策边界的绘制非常重要
y_axis.shape

# 将 x_axis 和 y_axis 展平，转化为一维数组，以便用来做预测
# 使用 ravel() 或者 flatten() 展平 2D 数组
x_axis_ravel = x_axis.ravel()
y_axis_ravel = y_axis.ravel()

# 合并两个一维数组，得到所有网格坐标的二维形式
# np.c_[] 用来按列将两个一维数组合并成一个二维数组
xy_axis = np.c_[x_axis_ravel, y_axis_ravel]

# 4. KNN预测与绘制决策边界
# 对所有坐标点进行分类预测，knn.predict 返回的是对应点的预测标签
# knn.predict() 通过KNN模型对输入的二维数据（xy_axis）进行分类预测
knn_predict_result = knn.predict(xy_axis)

# 画图展示决策边界
# 创建一个新图形，设置图形尺寸
fig = plt.figure(figsize=(15, 20))

# 添加子图，ax 表示一个图形区域
# 111 表示 1 行 1 列的第一个图
ax = fig.add_subplot(111)

# contour: 绘制等高线，表示决策边界
# 第一个和第二个参数是坐标点网格，第三个参数是每个坐标点的预测标签
# 这里将预测结果（knn_predict_result）按网格的形状重塑，以便绘制边界
ax.contour(
    x_axis,  # x 轴坐标
    y_axis,  # y 轴坐标
    knn_predict_result.reshape(x_axis.shape),  # 将预测结果按网格形状重塑
)

# 绘制原始点的散点图
# ax.scatter 用于绘制散点，分为三个类别
# point_concat[point_concat_label == 0, 0]
# 和 point_concat[point_concat_label == 0, 1]
# 用于筛选属于类别 0 的点
ax.scatter(
    point_concat[point_concat_label == 0, 0],  # 类别 0 的 x 坐标
    point_concat[point_concat_label == 0, 1],  # 类别 0 的 y 坐标
    color="b",  # 蓝色
    marker="^",  # 使用三角形标记
)

ax.scatter(
    point_concat[point_concat_label == 1, 0],  # 类别 1 的 x 坐标
    point_concat[point_concat_label == 1, 1],  # 类别 1 的 y 坐标
    color="r",  # 红色
    marker="*",  # 使用星形标记
)

ax.scatter(
    point_concat[point_concat_label == 2, 0],  # 类别 2 的 x 坐标
    point_concat[point_concat_label == 2, 1],  # 类别 2 的 y 坐标
    color="y",  # 黄色
    marker="s",  # 使用方形标记
)

# 显示图形
# plt.show() 展示整个图形，确保图形可视化
plt.show()

```

#### 2.1.6 距离选择

##### 2.1.6.1 欧式距离

欧氏距离是最容易直观理解的两点之间的距离度量方法，也称为**直线距离**也称**L2 距离**。

**在二维空间中，欧氏距离其实就是“尺子量两点之间的直线长度”。就像你拿一根绳子在地图上拉直，量出 A 点到 B 点的直线距离——这就是欧氏距离。**
公式 2 维，3 维，n 维计算公式：
![1763603408419](image/machine-learning/1763603408419.png)
**缺点：** 在使用此距离度量之前，需要对数据进行标准化(不是绝对的)。随着数据维度的增加，欧式距离的用处也就越小。

> **为什么要“标准化”数据:** 主要目的是拉近数据之间的距离，不让数据过于分散
> 归一化（Normalization）：把数据压缩到「固定范围」，通常是 0 到 1。
> 标准化（Standardization）：让数据变成**均值为 0、方差为 1**，但范围不限。
> ⭐ 欧氏距离的数学公式本身不要求标准化但 ⭐ 在机器学习中，为了让欧氏距离更合理，常常会“先标准化，再计算欧氏距离”。
> 也就是说：标准化不是欧氏距离公式的一部分，而是使用欧氏距离前的准备工作。
> ![1763605275532](image/machine-learning/1763605275532.png)
> maen：均值。每个数据都减去均值，再计算均值时，均值会变为 0
> std：标准差.标准差表示数据的分散程度，标准差大分散程度大
> ![1763605437508](image/machine-learning/1763605437508.png)

##### 2.1.6.2 曼哈顿距离(Manhattan Distance)

定义：曼哈顿距离是计算两点之间**水平线段或垂直线段的距离之和**，也称为城市街区距离或**L1 距离**
eg:
在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离也称为“城市街区距离”(City Block distance)。
![1763608406704](image/machine-learning/1763608406704.png)
![1763608416361](image/machine-learning/1763608416361.png)

##### 2.1.6.3 切比雪夫距离 (Chebyshev Distance)

**定义：**切比雪夫距离是计算两点在各个**坐标上的差的绝对值**的**最大值**。
也就是从**维度上看**，例如二维空间 x,y 坐标系下，切比雪夫距离就是 x 坐标差值和 y 坐标插值的最大的那个
即切比雪夫距离就是两点之间，各个**维度上差值最大的那个**
对比曼哈顿距离，**切比雪夫距离**的**移动方向有八个**，它可以斜着走所以**切比雪夫距离永远 ≤ 曼哈顿距离**
![1763609864464](image/machine-learning/1763609864464.png)

##### 2.1.6.4 闵可夫斯基距离(Minkowski Distance)

![1763617633172](image/machine-learning/1763617633172.png)

> 其中 p 是一个变参数：
>
> 当 p=1 时，就是曼哈顿距离；
>
> 当 p=2 时，就是欧氏距离；
>
> 当 p→∞ 时，就是切比雪夫距离。
>
> 根据 p 的不同，闵氏距离可以表示某一类/种的距离。
>
> 小结：
>
> 1 闵氏距离，包括曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点:
>
> e.g. 二维样本(身高[单位:cm],体重[单位:kg]),现有三个样本：a(180,50)，b(190,50)，c(180,60)。
>
> a 与 b 的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于 a 与 c 的闵氏距离。
> 但实际上身高的 10cm 并不能和>体重的 10kg 划等号。
>
> 2 闵氏距离的缺点：
>
> (1)将各个分量的量纲(scale)，也就是“单位”相同的看待了;
>
> (2)未考虑各个分量的分布（期望，方差等）可能是不同的。
> (3) 使用参数 p 实际上可能会很麻烦

##### 2.1.6.4 余弦距离(Cosine Distance)

余弦相似度是两个向量之间的夹角余弦值，表示两个向量的方向差异，而不是长度差异。
二维空间中向量 A(x1,y1)与向量 B(x2,y2)的夹角余弦公式：

- 注意公式的分母是向量的模
  ![1763617448090](image/machine-learning/1763617448090.png)
  **缺点：** 余弦相似度无法捕捉向量的幅度信息，**只考虑方向。**

---

##### 2.1.6.5 杰卡德距离(Jaccard Distance)

**杰卡德相似系数(Jaccard similarity coefficient)：**两个集合 A 和 B 的交集元素在 A，B 的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号 J(A,B)表示：
![1763617318181](image/machine-learning/1763617318181.png)
**缺点：** 它受到数据大小的很大影响。大型数据集可能会对相似系数产生很大影响，因为**数据量很大的话可能显著增加并集**，同时保持交集不变。
杰卡德距离(Jaccard Distance)：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度：
![1763618710455](image/machine-learning/1763618710455.png)

---

#### 2.1.7 交叉验证方法

交叉验证是在机器学习**建立模型**和**验证模型参数**时常用的办法，一般被用于**评估**一个机器学习模型的**表现**。更多的情况下，我们也用交叉验证来进行**模型选择(model selection)**。
![1763619637843](image/machine-learning/1763619637843.png)

---

##### 2.1.7.1 HoldOut Cross-validation（Train-Test Split）（保留交叉验证）

在这种交叉验证技术中，整个数据集被随机地划分为**训练集**和**验证集**。根据经验法则，整个数据集的近 **70%**被用作**训练集**，其余 **30%**被用作**验证集**。也就是我们最常使用的，直接划分数据集的方法。
**作用：** 初步避免过拟合给出一次模型性能的估计
**缺点：** 只验证了一次，结果容易碰运气。如果刚好 30% 的数据比较简单/困难，结果就偏了。

##### 2.1.7.2 K-折交叉验证（K-fold Cross Validation，记为 K-CV）

模型的最终准确度是通过取 k 个模型验证数据的平均准确度来计算的。
![1763620963564](image/machine-learning/1763620963564.png)
**最常用** 的是 K 折交叉验证（K-Fold Cross-Validation）：

- 1.把数据平**均分成 K 份**
- 2.每次用 **K-1 份训练**，用**剩下一份验证**
- 3.一共训练验证**K 次**
- 4.对 K 次的结果取平均
- **例子：**
  第 1 次：1 折验证，2-5 折训练  
  第 2 次：2 折验证，1/3/4/5 折训练  
  第 3 次：3 折验证  
  第 4 次：4 折验证  
  第 5 次：5 折验证
  模型被“考试”了 5 次，每次用不同的考卷，最后取平均成绩。

**交叉验证作用：**

- 1.评估模型性能是否稳定
- 2.选择最佳模型
- 3.选超参数（超参数调优）:如网格搜索（Grid Search）+ 交叉验证是经典组合。
- 4.避免过拟合:因为模型被验证了多次，每次都是新的未见数据。

---

> **1.什么是超参数：**
> 超参数是训练之前你必须**人为设定的参数**，模型不会自己学出来。**例如 KNN 算法中的 K**
> 它们是“规则”“配置”“策略”，不是模型从数据中学到的东西。
> 你可以把模型比作一位学生：
>
> - **参数（parameters）** = 学生从书里学到的知识（模型训练出来的权重）
> - **超参数（hyperparameters）** = 老师定的规则（学习速度、多少章节、坐哪里、考试多少次）
>   模型自己学不了超参数，只能听你的。

---

> **2.什么是过拟合：**
> 模型把训练数据学得太死板，把噪声、细节、意外情况都背下来了，导致在新数据上表现很差。
>
> **模型复杂** → 容易把噪声当规律
> **模型简单** → 容易抓不到规律（欠拟合）
>
> **出现过拟合的核心原因：**
> 当模型复杂度大到足以“死死贴住训练数据”时，它会做出非常奇怪的决策边界：
>
> - 决策树可以无限分裂，最后把每个样本都单独隔开
> - 神经网络层数太多，会拟合所有细节
> - KNN 取 K=1，会把每个点都当成规则

---

| 模型     | 超参数        | 超参数增大 → 复杂度 ↑ → 过拟合 ↑ |
| -------- | ------------- | -------------------------------- |
| 决策树   | max_depth     | 深度越大，越容易过拟合           |
| KNN      | K             | K 越小越过拟合                   |
| SVM      | C             | C 越大，越允许错误越少，越过拟合 |
| 神经网络 | hidden layers | 层数越多越过拟合                 |

---

#### 2.1.8 Scikit-learn 实现 KNN 算法

**实现步骤：**

1. 获取数据集
2. 数据基本处理(该案例中省略此步骤)
3. 特征工程(该案例中省略此步骤)
4. 机器学习
5. 模型评估(该案例中省略此步骤)

---

##### 2.1.8.1 KNN 算法中的 API 解读

###### 2.1.8.1.1 KNeighborsClassifier

---

**为什么 KDTree / BallTree 需要叶子节点:**

> **KDTree** 和 **BallTree** 本质上是：
>
> 把**数据点分割成一棵树**，让查询某个点的最近邻时不用比较所有点，而是从树结构快速排除大量无关区域。
> 树越有效，最近邻搜索越快。
> 而树有两部分：
>
> - 非叶子节点：做空间划分
> - 叶子节点：最终装“数据点的那一片区域”(所有数据都在这)

---

**leaf_size（叶子节点大小）是什么:**

> 假设你有数据点 1000 个，如果 leaf_size=10，那么你的树大概会有：
> 1000 / 10 ≈ 100 个叶子节点
> 如果 leaf_size=50：
> 1000 / 50 ≈ 20 个叶子节点

---

**leaf_size 为什么会影响“速度”：**

| leaf_size 小           | leaf_size 大           |
| ---------------------- | ---------------------- |
| 树深，层数多           | 树浅，层数少           |
| 构建慢                 | 构建快                 |
| 最终叶子点少、查询快   | 最终叶子点多、查询慢   |
| 更节省空间             | 占更多空间             |
| 查找效率更高（小数据） | 查找效率下降（大数据） |

---

```python


class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)
    参数说明：

    @ n_neighbors: int, 可选参数(默认为 5)用于kneighbors查询的默认邻居的数量

    @ weights（权重）: str or callable(自定义类型), 可选参数(默认为 ‘uniform’)

        用于预测的权重函数。可选参数如下:

            ‘uniform’ : 统一的权重. 在每一个邻居区域里的点的权重都是一样的。
            ‘distance’ : 权重点等于他们距离的倒数。使用此函数，更近的邻居对于所预测的点的影响更大。
            [callable] : 一个用户自定义的方法，此方法接收一个距离的数组，然后返回一个相同形状并且包含权重的数组。

    @ algorithm（算法）: {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, 可选参数（默认为 ‘auto’）

        计算最近邻居用的算法：
            ‘ball_tree’ 是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。
            ‘kd_tree’ 构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。
            ‘brute’ 使用暴力搜索.也就是线性扫描，当训练集很大时，计算非常耗时
            ‘auto’ 会基于传入fit方法的内容，选择最合适的算法。

    @ leaf_size（叶子数量）: int, 可选参数(默认为 30)

        传入BallTree或者KDTree算法的叶子数量。此参数会影响构建、查询BallTree或者KDTree的速度，以及存储BallTree或者KDTree所需要的内存大小。 此可选参数根据是否是问题所需选择性使用。

    @ p: integer, 可选参数(默认为 2)

        用于Minkowski metric（闵可夫斯基空间）的超参数。p = 1, 相当于使用曼哈顿距离 (l1)，p = 2, 相当于使用欧几里得距离(l2) 对于任何 p ，使用的是闵可夫斯基空间(l_p)

    @ metric（矩阵）: string or callable, 默认为 ‘minkowski’

        用于树的距离矩阵。默认为闵可夫斯基空间，如果和p=2一块使用相当于使用标准欧几里得矩阵. 所有可用的矩阵列表请查询 DistanceMetric 的文档。

    @ metric_params（矩阵参数）: dict, 可选参数(默认为 None)

        给矩阵方法使用的其他的关键词参数。

    @ n_jobs: int, 可选参数(默认为 1)

        用于搜索邻居的，可并行运行的任务数量。如果为-1, 任务数量设置为CPU核的数量。不会影响fit方法。

```

---

##### 2.1.8.1.2 fit(机器学中一般都称为训练)

拟合模型就是让一个“数学函数”去尽量贴合（fit）你手里的数据。

```python
fit(X,y):

    使用X作为训练数据，y作为目标值（标签）拟合模型
参数:

    @ X: {类似数组, 稀疏矩阵}
     稀疏矩阵是指在一个 矩阵中 ，大多数元素为零，只有少数元素为非零值的矩阵 。形式上，给定一个 m x n 的矩阵 A，如果 A 中非零元素的
数量远小于 m x n，则称 A 为稀疏矩阵

        待训练数据。如果是数组或者矩阵，形状为 [n_samples, n_features]，如果矩阵为’precomputed’, 则形状为[n_samples, n_samples]。

    @ y: {类似数组, 稀疏矩阵}
        形状为[n_samples] 或者 [n_samples, n_outputs]的目标值。
```

##### 2.1.8.1.3 get_params

```python
get_params(deep=True)

    获取估值器的参数.
参数:

    @ deep: boolean, 可选参数

        如果为 True, 则返回估值器的参数，以及包含子目标的估值器。

返回值:

    @ params: Mapping string to any

        返回Map变量，内容为[参数值: 值, 参数值: 值, …]。
```

##### 2.1.8.1.4 kneighbors

```python
kneighbors(X=None,n_neighbors=None,return_distance=True)[source]

    查询一个或几个点的K个邻居, 返回每个点的下标和到邻居的距离。
    （重点使用）

参数:

    @ X: 类似数组, 形状(n_query, n_features)或者(n_query, n_indexed) 。

        如果矩阵是‘precomputed’，形状为(n_query, n_indexed)带查询的一个或几个点。如果没有提供，则返回每个有下标的点的邻居们。

    @ n_neighbors: int

        邻居数量 (默认为调用构造器时设定的n_neighboes的值).

    @ return_distance: boolean, 可选参数. 默认为 True.

        如果为 False，则不会返回距离

返回值:

dist: array

    当return_distance =True时，返回到每个点的长度。

ind: array

    邻居区域里最近的几个点的下标。
```

##### 2.1.8.1.5 predict

```python
predict(X)[source]

给提供的数据预测相应的类别标签

参数:

    @ X: 类似数组, 形状(n_query, n_features)。

        如果矩阵是‘precomputed’，形状为(n_query, n_indexed) 待测试样例。

返回值:

    @ y: 形状为 [n_samples] 或者 [n_samples, n_outputs]的数组

        返回每个待测试样例的类别标签。
```

##### 2.1.8.1.5 predict_proba

```python
predict_proba(X)[source]

    返回测试数据X的概率估值。
参数:

    @ X: 类似数组, 形状(n_query, n_features)。

        如果矩阵是‘precomputed’，形状为(n_query, n_indexed)待测试样例。

返回值:

    @ p: 形状为[n_samples, n_classes]的数组，或者是n_outputs列表

        输入样例的类别概率估值。其中类别根据词典顺序排序。
```

##### 2.1.8.1.6 score

```python
score(X, y, sample_weight=None)[source]

    返回给定测试数据和标签的平均准确度。在多标签分类中，返回的是各个子集的准确度。

参数:

    @ X : 类似数组，

        形状为 (n_samples, n_features)待测试样例

    @ y: 类似数组，

        形状为 (n_samples) 或者 (n_samples, n_outputs)X对于的正确标签

    @ sample_weight: 类似数组，

        形状为 [n_samples], 可选参数待测试的权重

返回值:

    @ score : float

        self.predict(X) 关于y的平均准确率。
```

#### 2.1.9 KNN 算法实现鸢尾花数据集分类

##### 2.1.9.1 数据集介绍

iris 数据集是常用的分类实验数据集，由 Fisher 在 1936 收集整理。Iris 也称为鸢尾花卉数据集，是一类多重变量分析的数据集。
![1763635624031](image/machine-learning/1763635624031.png)

Iris 鸢尾花数据集： 包含 3 个目标值分别为：

- 山鸢尾（Iris-setosa）；
- 变色鸢尾（Iris-versicolor）；
- 尼亚鸢尾（Iris-virginica），

包含 4 个特征值：

- Sepal.Length（花萼长度），单位是 cm;
- Sepal.Width（花萼宽度），单位是 cm;
- Petal.Length（花瓣长度），单位是 cm;
- Petal.Width（花瓣宽度），单位是 cm;

共 150 条数据，每类各 50 个数据，每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，通常可以通过这 4 个特征预测鸢尾花卉属于哪一品种。

##### 2.1.9.2 Scikit-Learn 中的数据集介绍

```python
# 鸢尾花数据集获取

    from sklearn.datasets import load_iris

    # 小规模数据集获取
    iris = load_iris()

    print(iris)
```

##### 2.1.9.3 sklearn 数据返回值介绍

```python
load_iris返回的数据类型datasets.base.BUnch（字典格式）
    data : 特征数据数组，是[n_samples * n_features]的二维numpy.ndarray数组
    target ： 标签数组，是n_samples的一维numpy.ndarray数组
    DESCR ： 数据描述
    feature_names : 特征名， 新闻数据，手写数字，回归数据没有
    target_name : 标签名(目标明)
```

##### 2.1.9.4 数据集划分

机器学习一般的数据集划分分为两部分 1. 训练数据：用于训练，构建模型 2. 测试数据：在模型校验时使用，用于评估模型是否有效
划分比例： 1. 训练集 ： 70% 80% 75% 2. 测试集 ： 30% 20% 25%

```python
数据集划分API
    sklearn.model_selection.train_test_split(arrays, *options)
        x ： 数据集的特征值
        y ： 数据集的标签特征值
        test_size : 测试集占的的大小， 一般为float
        random_state : 随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。
        return : 测试机特征训练集特征值，训练标签，测试标签(默认随机取)
```

```python
#获取鸢尾花的数据集
from sklearn.datasets import load_iris

#查看一下数据集
iris=load_iris()
#数据集划分
from sklearn.model_selection import train_test_split
#第一个参数表示训练数据  第二个参数为训练数据标签 第三个是按照比例划分训练集和测试集
x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target, test_size=0.2)
# print("训练集的特征值是 ： \n", x_train)
# print("测试集的特征值是 ： \n", x_test)
# print("训练集的目标值是 ： \n", y_train)
# print("测试集的目标值是 ： \n", y_test)

print("训练集的特征值形状 ： \n", x_train.shape)
print("测试集的特征值形状 ： \n", x_test.shape)
print("训练集的目标值形状 ： \n", y_train.shape)
print("测试集的目标值形状 ： \n", y_test.shape)

```

#### 2.1.10 KNN 算法的优缺点

**优点：**

1. 简单
2. 易于理解
3. 容易实现
4. 通过 K 值的选择可具备丢掉噪音数据的健壮性。
5. 适合类域交叉样本，KNN ⽅法主要靠周围有限的邻近的样本,⽽不是靠判别类域的⽅法来确定所属类别的，因此对于类域的交 叉或重叠较多的待分样本集来说，KNN ⽅法较其他⽅法更为适合。

**缺点：**

1. 惰性学习，KNN 算法是懒散学习⽅法（lazy learning,基本上不学习），⼀些积极学习的算法要快很多
2. 需要大量空间存储已知实例
3. 对不均衡的样本不擅⻓，当样本不平衡时，如⼀个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的 K 个邻居中大容量类的样本占多数。影响最后的输出类别。
4. 算法复杂度高，需要比较所有已知实例与要分类的实例。

### 2.2 前向传播与损失函数反向传播的学习率与梯度下降

神经网络中**前向传播、损失函数与反向传播**的整体作用（结构化笔记版）

1. **前向传播：负责生成预测结果**
   前向传播将输入数据按网络结构逐层传递，通过当前的权重和偏置计算出最终的预测值。它相当于模型“用现有知识做出一次判断”。

2. **损失函数：用于量化预测误差**
   损失函数衡量模型预测与真实标签之间的差异，将“预测对不对”转化为一个可优化的数值指标。损失越小，模型表现越好，为后续更新提供依据。

3. **反向传播：根据误差调整参数**
   反向传播利用损失函数的结果，通过链式求导计算每个参数对误差的影响（梯度），并将这些梯度从输出层向输入层反向传播。梯度越大，说明该参数对错误的贡献越大，需要更明显的调整。

4. **参数更新：让模型不断改进**
   在获得梯度后，优化算法（如梯度下降）会根据梯度方向更新权重与偏置，使损失不断减少。模型通过一轮轮迭代，逐渐提高预测准确性。

5. **形成完整的学习闭环**
   整个学习过程可以概括为：
   前向传播得到预测 → 损失函数计算误差 → 反向传播计算梯度 → 参数更新修正模型
   这四个步骤循环往复，使神经网络能够从数据中自动学习并不断提升性能。

**神经网络各层结构理解：**

| 层类型                      | 作用（它负责干什么）                 | 结构（里面有什么）       | 数学运算                                 | 神经元数量由什么决定   | 是否有激活函数 | 是否参与训练 |
| --------------------------- | ------------------------------------ | ------------------------ | ---------------------------------------- | ---------------------- | -------------- | ------------ |
| **输入层（Input Layer）**   | 接收原始数据，不做运算               | 只是数据的入口           | 无                                       | = 输入特征数量         | ❌ No          | ❌ No        |
| **隐藏层（Hidden Layers）** | 提取特征、加工信息，是学习能力的核心 | 神经元 + 权重 W + 偏置 b | ( z = Wx + b )，再做激活 ( a=\sigma(z) ) | 由你自己设计（超参数） | ✔ Yes          | ✔ Yes        |
| **输出层（Output Layer）**  | 产出最终结果（概率/类别/数值）       | 神经元 + 权重 W + 偏置 b | 根据任务不同决定是否加激活               | 与任务类型相关         | 部分需要       | ✔ Yes        |

![1763904597305](image/machine-learning/1763904597305.png)

#### 2.2.1 数学

##### 求导

![1763950706945](image/machine-learning/1763950706945.png)
![1763950694616](image/machine-learning/1763950694616.png)
![1763950771746](image/machine-learning/1763950771746.png)
![1763951036596](image/machine-learning/1763951036596.png)
![1763951162016](image/machine-learning/1763951162016.png)
![1763951295866](image/machine-learning/1763951295866.png)
![1763951388163](image/machine-learning/1763951388163.png)
![1763951465406](image/machine-learning/1763951465406.png)
![1763951595083](image/machine-learning/1763951595083.png)
![1763951625633](image/machine-learning/1763951625633.png)
![1763951990746](image/machine-learning/1763951990746.png)
![1763952170884](image/machine-learning/1763952170884.png)
![1763952178259](image/machine-learning/1763952178259.png)
![1763952271121](image/machine-learning/1763952271121.png)
![1763952423650](image/machine-learning/1763952423650.png)
![1763952577128](image/machine-learning/1763952577128.png)
![1763952661330](image/machine-learning/1763952661330.png)

##### 梯度

![1763691101631](image/machine-learning/1763691101631.png)

#### 2.2.2 前向传播与损失函数

以下 2 个方面对前向传播与损失函数进行介绍

1. 前向传播与损失函数理论讲解
2. 编程实例与步骤

上面这 2 方面的内容，让大家，掌握并理解前向传播与损失函数。

##### 2.2.2.1 前向传播论讲解

###### 2.2.2.1.1 前向传播的定义

![1763691550892](image/machine-learning/1763691550892.png)

###### 2.2.2.1.2 前向传播的过程

1. **输入层：把数据送进网络**
   ![1763691898683](image/machine-learning/1763691898683.png)
2. **输入层 → 隐藏层：线性变换 + 非线性激活**
   ![1763691880499](image/machine-learning/1763691880499.png)
3. **隐藏层 → 输出层：再来一次线性变换 + 输出计算**
   ![1763691965889](image/machine-learning/1763691965889.png)

```scss
输入数据 x
     ↓
[输入层]  —(把数据交给下一层)→
     ↓
[隐藏层] 线性变换：W·x + b
     ↓
        激活函数：f()
     ↓
[输出层] 线性变换：W2·a + b2
     ↓
输出结果 ŷ
```

###### 2.2.2.1.3 前向传播的作用

对数据的输入逐步处理，提取对应的特征，并进行预测.
**根据当前的模型参数**，把输入转成输出，也就是让模型做 **“预测”**。
它不是在“学习”，不是在“更新参数”，它**只负责 “算一次结果”**。

##### 2.2.2.2 损失函数理论讲解

###### 2.2.2.2.1 损失函数定义

**损失函数（Loss Function）** 是神经网络和机器学习模型的 **“误差测量器”**。
它的作用就是告诉我们：

> 模型的预测结果离真实答案还有多远。

你可以把它理解成“成绩单”或“偏差量表”：

如果**损失值很小**，模型的预测很**接近真实结果**

如果**损失值很大**，模型预测得很**差**

> 在训练过程中，我们会不断让模型前向传播得到预测，再计算损失值，然后通过反向传播让模型调整参数，让损失越来越小。

---

> 损失函数就是帮助模型“知道自己错在哪、错了多少”的工具。

没有损失函数，模型就无法学习，因为它根本不知道应该往哪个方向改。

**损失函数**用于衡量**模型预测与真实标签之间的误差**，是训练过程中指导模型**调整参数的核心依据**。通过**最小化损失函数**，模型能够逐步**改进预测性能**。

#### 2.2.3 其他概念

##### 案例引入

![1763693020379](image/machine-learning/1763693020379.png)

##### 案例前向计算

![1763693169600](image/machine-learning/1763693169600.png)

##### 单点误差

由下图可知，当 w 等于 2 的时候“拟合”这些散点和实际的坐标点 y 轴的差距，由图上的绿色虚线表示。绿色虚线表示每一个**真实的数据点和预测的数据点的差距**，也就是**数据点损失**。
![1763693439586](image/machine-learning/1763693439586.png)

##### 损失函数：均方差

理解，这里做的拟合，x 是传入的数据集，虽然 x 是自变量，改变 x 求出不同的 y。但是，数据集是固定不变的，我们实际调整的参数是 w 和 b。所以画图时，这个维度的考虑是由这两部分决定的
![1763694726077](image/machine-learning/1763694726077.png)
![1763694545566](image/machine-learning/1763694545566.png)

---

**判断“最佳损失函数”的核心标准:**

1. **能准确表达任务目标（最重要）**
   **损失函数必须与任务本质一致。** 例如：

   - 分类任务 → 使用交叉熵最合适
   - 回归任务 → 使用 MSE / MAE / Huber Loss
   - 排序任务 → 使用 Ranking Loss  
     任务不匹配会导致再强的模型也学不好。

2. **必须可导（至少大部分地方可导）**
   **神经网络依赖梯度来更新参数**，因此损失函数需要可 求导，以支持反向传播。

3. **梯度稳定，不爆炸、不消失**
   一个好的损失函数要有合理的梯度变化：

   - MSE 容易被异常值放大
   - MAE 梯度恒定，学习慢
   - Huber Loss 在稳定性上表现最佳

4. **对噪声和异常值具有鲁棒性**
   损失函数要能在面对脏数据或离群点时表现稳定： - 分类：交叉熵对概率分布敏感但梯度稳定 - 回归：Huber Loss 在异常点处表现优于 MSE 和 MAE

5. **容易优化、收敛速度快**
   好的损失函数具有光滑的曲线形状和稳定的梯度方向，使得模型在训练过程中更容易收敛，而不会振荡或滞。

---

**不同任务中实际表现“最佳”的损失函数:**

1. 回归任务（预测连续值）

   - **Huber Loss（最佳综合表现）**
   - MSE（简单但对异常值敏感）
   - MAE（抗噪但梯度恒定）

2. 二分类任务

   - **Binary Cross Entropy（最佳）**

3. 多分类任务

   - **Softmax Cross Entropy（最佳）**

4. 目标检测框回归

   - **Smooth L1 Loss（行业标配）**

5. 排序任务（搜索、推荐）

   - Ranking Loss / Triplet Loss（最符合排序本质）

6. GAN 生成模型

   - Hinge Loss / Non-saturating Loss（更稳定）

#### 2.2.4 反向传播的学习率与梯度下降

##### 2.2.4.1 反向传播的学习率与梯度下降起什么作用？

反向传播的学习率与梯度下降起的作用就是对前向传播中的参数进行更新(改变参数的值(w))。

##### 2.2.4.2 反向传播的概念

反向传播是在前向传播后进行的，它是对前向传播过程中的参数进行更新的一个过程，通过最小化损失函数来优化模型参数。

##### 2.2.4.3 案例导入

![1763707722610](image/machine-learning/1763707722610.png)

##### 2.2.4.3 前向传播与反向传播的区别

- 前向传播负责根据当前参数计算预测；
- 损失函数负责衡量预测误差；
- 反向传播负责根据误差自动更新参数。

> 前向用于 **“看结果”** ，反向用于 **“改参数”** ，**两者循环往复**，使神经网络能够不断学习和提升预测能力。

**前向传播**和**反向传播**是神经网络学习过程中**彼此依赖**的两个核心步骤，它们分别承担**计算预测**和**更新参数**的任务。

1. **前向传播：固定参数，计算预测**

   前向传播是在参数固定的情况下，将**输入数据依次传入模型各层**，通过公式计算得到**预测结果**的过程。
   换句话说，前向传播回答的是：

   > “用当前的参数，模型会给出什么样的预测？”

   如果当前参数（如权重 w、偏置 b）选择得不合适，模型的输出就会偏离真实值。在手动实验中，我们会通过不 断调整 w 来观察预测曲线是否更贴近散点，从而形象地理解前向传播的作用。

2. **损失反馈：判断预测好坏**

   完成前向传播后，我们需要计算损失函数，**用一个数值来衡量预测值与真实值之间的差距**。损失越大，说明当前参数越差；损失越小，说明当前参数更合理。

   这一步是**前向传播与反向传播之间的桥梁**。

3. **反向传播：根据误差自动调整参数**

   反向传播发生在前向传播和损失计算之后，它负责**根据损失函数的值**，**计算每个参数对误差的贡献程度（即梯度）**，并按照一定规律（通常是梯度下降）更新参数。

   反向传播回答的问题是：

   “为了让预测更准确，参数应该如何修改？”

   与前向传播的“算结果”不同，**反向传播的核心是“修正模型”**。

---

神经网络学习流程图（ASCII 图）

```mathematica
                 ┌─────────────────────────┐
                 │        输入数据 x        │
                 └─────────────┬───────────┘
                               │
                               ▼
                  ┌────────────────────────┐
                  │      前向传播 Forward   │
                  │  利用当前参数计算预测 ŷ │
                  └─────────────┬──────────┘
                                │
                                ▼
                  ┌────────────────────────┐
                  │     损失计算 Loss       │
                  │  L = Loss(y, ŷ)         │
                  │  衡量预测与真实的差距    │
                  └─────────────┬──────────┘
                                │
                                ▼
                  ┌────────────────────────┐
                  │   反向传播 Backward     │
                  │  计算梯度 ∂L/∂w, ∂L/∂b    │
                  │  分析每个参数的错误贡献   │
                  └─────────────┬──────────┘
                                │
                                ▼
                  ┌────────────────────────┐
                  │     参数更新 Update     │
                  │  w ← w - η·∂L/∂w        │
                  │  b ← b - η·∂L/∂b        │
                  │  （让损失变得更小）      │
                  └─────────────┬──────────┘
                                │
                                ▼
                ┌──────────────────────────────────┐
                │   循环往复：直到损失足够小或收敛   │
                └──────────────────────────────────┘

```

##### 2.2.4.4 求损失函数以及损失函数的形态

![1763708358067](image/machine-learning/1763708358067.png)

##### 2.2.4.5 参数初始化

![1763708678906](image/machine-learning/1763708678906.png)

##### 2.2.4.6 梯度下降的概念

在机器学习中，梯度表示损失函数对于模型参数的偏导数，梯度下降是机器学习中一种常用的优化算法。
它的基本思想是在训练过程中通过不断调整参数，使损失函数 **（代表模型预测结果与真实结果之间的差距）** 达到最小值。
为了实现这一目标，梯度下降算法会计算损失函数的梯度 **（带方向的斜率）**，然后根据梯度的方向更新权重，使**损失函数不断减小。**
对于一个模型来说，我们可以计算每一个权重对损失函数的影响程度，然后**根据损失函数的梯度来更新这些权重**。通过不断重复这一过程，我们就可以找到一组使损失函数最小的权重值，从而训练出一个优秀的模型。
![1763709000440](image/machine-learning/1763709000440.png)假设你在一个陌生的山地上，你想找到一个谷底，那么肯定是想沿着向下的坡行走，如果想尽快的走到谷底，那么肯定是要沿着最陡峭的坡下山。每走一步，都找到这里位置最陡峭的下坡走下一步，这就是**梯度下降**。
在这个比喻中，梯度就像是山上的坡度，告诉我们在当前位置上地势变化最快的方向。
为了尽快走向谷底，我们需要沿着最陡峭的坡向下行走，而梯度下降算法正是这样的方法。
每走一步，我们都找到当前位置最陡峭的下坡方向，然后朝着该方向迈进一小步。这样，我们就在梯度的指引下逐步向着谷底走去，直到到达谷底 **（局部或全局最优点）**。
在机器学习中，**梯度表示损失函数对于模型参数的偏导数**。具体来说，对于每个可训练参数，梯度告诉我们在当前参数值下，沿着每个参数方向变化时，损失函数的变化率。
通过计算损失函数对参数的梯度，**梯度下降算法能够根据梯度的信息来调整参数，朝着减少损失的方向更新模型**，从而逐步优化模型，使得模型性能更好。
在 $\bar e={\frac{1}{n}}\sum_{i=1}^{n}x_{i}^{2}w^{2}-{\frac{2}{n}}\sum_{i=1}^{n} x_{i}y_{i}w+{\frac{1}{n}}\sum_{i=1}^{n} y_{i}^{2}$ 这个二元一次方程中，损失函数对于参数 w 的梯度就是关于 w 点的切线斜率。
梯度下降算法会根据该斜率的信息来调整参数 w，使得损失函数逐步减小，从而找到使得损失最小化的参数值，优化模型的性能。
![1763709328680](image/machine-learning/1763709328680.png)

##### 2.2.4.7 梯度下降法的优化方法

在损失函数关于 w 的表达式中，确实存在一个 w，使得损失函数的值最小。下面使用三种方案，包括**固定值法**、**斜率法**、**小固定值\*斜率法**，展示一下其不同的优化效果。

###### 2.2.4.7.1 方案 1：固定值法

在更新 w 的时候，采用旧的 w 减去一个固定的值的方法其公式如下所示：
![1763709646761](image/machine-learning/1763709646761.png)
固定值的弊端有两个：

1. 当固定值的正负确定后，就意味着 w 的更新方向确定了，比如 w>0 时，且固定值为正数时，w 的值是不断减小的，w<0 时，固定值为负数时，w 的值是不断变大的。
2. 不能够准确的更新到令损失值最小的 w 值，比如最合适的 w 值为 0.8，现在的 w 值为 1，而固定值为 0.5，那么就会跳过 0.8，直接变成 0.5，并且如果还没迭代完，还会变成 0，-0.5，…。
   也就是说，想通过该方法更新到最好的 w 值，要么事先算好，要么碰运气，总之效果很差。

**先搞清楚：1：固定值法到底是什么？**
![1763711423786](image/machine-learning/1763711423786.png)
也就是说：

- 不管损失函数长什么样
- 不管当前 𝑤 离最佳值远还是近
- 不管你往左走是更好还是更坏

你都只是机械地往同一个方向挪同样大的一步。这就是它的问题所在。
![1763711541599](image/machine-learning/1763711541599.png)
![1763711618645](image/machine-learning/1763711618645.png)
![1763711652464](image/machine-learning/1763711652464.png)

###### 2.2.4.7.2 方案 2：斜率法

**求斜率公式如何推导出来！！！！**
![1763716629575](image/machine-learning/1763716629575.png)
![1763716648527](image/machine-learning/1763716648527.png)
斜率法其实是“**只看梯度方向，不控制步长**”的最原始梯度法。它比“固定值法”聪明得多，但依然不够成熟
在这里它就是损失函数曲线中的 w 点的切线，斜率还有个很好的特性，那就是当 w 小于最低点对应的 w 时，它是负的；当 w 大于最低点对应的 w 时，它是正的。

- 当$w_{当前}>w_{最佳}$时：$w_新=w_旧-正数$；
- 当$w_{当前}<w_{最佳}$时：$w_新=w_旧-负数$。
  其公式如下所示：
  > $w_新=w_旧-斜率$

![1763711995948](image/machine-learning/1763711995948.png)
**斜率法的弊端：**
当损失函数比较陡峭时，斜率值很大，会来回震荡，并且斜率值越来越大，损失函数值也会越来越大，效果也不是很理想。
你可以这样理解：

- 梯度小 → 步子小
- 梯度大 → 步子大到离谱
  ![1763712552131](image/machine-learning/1763712552131.png)

###### 2.2.4.7.3 方案 3：斜率法

斜率有很好的特性，但是斜率值太大了不受控制，那么是不是可以把斜率，也就是梯度的值乘以一下很小的数（小于 1）。
其公式如下所示：

> $w_新=w_旧-小固定值\cdot 斜率$

式子中的**小固定值被称为学习率**，通过改变学习率的值能**调整 w 的更新速度**，而整个式子就叫做**梯度下降（Gradient Descent，GD）**，是一种优化函数，作用是**最小化损失函数**。

![1763713106726](image/machine-learning/1763713106726.png)

##### 2.2.4.8 学习率的概念

在机器学习中，**学习率是一个超参数(超参数就是需要人为设置的参数)**，用于**控制权重(w)更新的速度**。通常来说，学习率越大，参数更新就越快，模型就学习的越快，但如果学习率过大，模型可能会不稳定，甚至无法收敛到最优解。因此，确定一个合适的学习率是非常重要的。

### 2.3 线性回归

#### 2.3.1 什么是线性回归

##### 2.3.1.1 定义

**线性回归**是一种用于建立自变量与因变量之间关系的统计方法。
它假设**因变量（或响应变量）**与一个或多个**自变量（或预测变量）**之间的关系是线性的。
其主要目标是通过**拟合一个线性模型**来**预测因变量**的数值。
![1763905566389](image/machine-learning/1763905566389.png)

##### 2.3.1.2 线性回归方程是什么

![1763905633369](image/machine-learning/1763905633369.png)

![1763906023239](image/machine-learning/1763906023239.png)
![1763907561073](image/machine-learning/1763907561073.png)
![1763907572797](image/machine-learning/1763907572797.png)
![1763907610427](image/machine-learning/1763907610427.png)
![1763907623760](image/machine-learning/1763907623760.png)
![1763907657149](image/machine-learning/1763907657149.png)

##### 2.3.1.3 散点输入

![1763905692007](image/machine-learning/1763905692007.png)

##### 2.3.1.4 参数初始化

###### 2.3.1.4.1 参数定义

模型中可调整的变量，它们用来捕捉数据中的**模式和特征**。这些参数在模型训练过程中被不断**调整**以**最小化损失函数**或**优化某种目标**。

###### 2.3.1.4.2 参数内容

**权重（Weights）：** 用来表示不同输入特征与神经元之间的**连接强度**
**偏置（Biases）：** 用于调整每个神经元的**激活阈值**，使模型能够更好地拟合数据。

###### 2.3.1.4.3 超参数定义

超参数不是通过训练数据学习得到的，而是在**训练过程之前**需要**手动设置的参数**。

###### 2.3.1.4.4 超参数内容

包括**学习率、正则化参数、迭代次数、批量大小、神经网络层数和每层的神经元数量、激活函数**。
**学习率（Learning Rate）**：用于**控制**优化算法中每次更新参数时的**步长**。较小的学习率会导致训练收敛较慢，而较大的学习率可能导致训练不稳定或震荡。
**正则化参数（Regularization Parameter）**：用于控制正则化的强度，如 L1 正则化和 L2 正则化。较大的正则化参数会增强正则化效果，有助于**防止过拟合**。
**迭代次数（Number of Iterations）**：用于控制训练的迭代次数。迭代次数太小可能导致模型未完全学习数据的特征，而迭代次数太大可能导致过拟合。
**批量大小（Batch Size）**：用于控制每次训练时用于更新参数的**样本数量**。批量大小的选择会影响**训练速度和内存消耗**。
**神经网络层数和每层的神经元数量（Number of Layers and Neurons per Layer）**：用于定义神经网络的结构。
**激活函数（Activation Function）**：用于控制神经网络**每个神经元**的**输出范围**，如 Sigmoid、ReLU 等。

##### 2.3.1.5 参数设定

![1763955824824](image/machine-learning/1763955824824.png)

##### 2.3.1.6 损失函数计算

![1763956029196](image/machine-learning/1763956029196.png)

##### 2.3.1.6 开始迭代

![1763956052577](image/machine-learning/1763956052577.png)

##### 2.3.1.7 反向传播

![1763956062572](image/machine-learning/1763956062572.png)

##### 2.3.1.8 显示频率设置

![1763956141182](image/machine-learning/1763956141182.png)

##### 2.3.1.9 梯度下降显示

![1763956206950](image/machine-learning/1763956206950.png)

### 2.4 PyTorch 的 tensor

#### 2.4.1 PyTorch 是什么

![1763965149367](image/machine-learning/1763965149367.png)

<https://pytorch.org/docs/stable/index.html>

#### 2.4.2 PyTorch 特点

![1763965218014](image/machine-learning/1763965218014.png)

#### 2.4.3 tensor 是什么

![1763965292633](image/machine-learning/1763965292633.png)

#### 2.4.5 tensor 的存储机制

##### 2.4.5.1 tensor

在 PyTorch 中，**tensor** 包含了两个部分，即 **Storage** 和 **metadata**。
**Storage(存储)**：存储是 tensor 中包含的**实际的底层缓冲区**，它是**一维数组**，存储了 tensor 的元素值。**不同 tensor 可能共享相同的存储**，即使它们具有不同的形状和步幅。**存储是一块连续的内存区域，实际上存储了 tensor 中的数据**。
**Metadata(元数据)**：元数据是 tensor 的**描述性信息**，包括 **tensor 的形状、数据类型、步幅、存储偏移量、设备等**。元数据提供了关于 tensor 的结构和属性信息，但并不包括 tensor 中的实际数据。**元数据允许 PyTorch 知道如何正确地解释存储中的数据以及如何访问它们**。
![1763968627021](image/machine-learning/1763968627021.png)
**有关步长、偏移量的相关解释看代码文件**

##### 2.4.5.2 数据类型

![1763970995563](image/machine-learning/1763970995563.png)

**torch.Float16**，也被称为 **FP16 或半精度浮点数**，是一种用于表示浮点数的数据类型，在计算机科学中广泛应用于各种领域。以下是对 Float16 的详细说明
![1763972012800](image/machine-learning/1763972012800.png)
![1763972066984](image/machine-learning/1763972066984.png)

Storage 存储的具体过程
在 PyTorch 中，张量的存储是通过 torch.Storage 类来管理的。张量的值被分配在连续的内存块中，这些内存块中，这些内存块是大小可变的一维数组，可以包含不同类型的数据，如 float 或 int32。
具体来说，当我们创建一个张量时，PyTorch 会根据我们提供的数据和指定的数据类型来分配一块连续的内存空间。这块内存空间由 torch.Storage 对象管理，而张量本身则提供了一种视图，让我们可以通过索引来访问这些数据。
此外，PyTorch 还提供了一系列的函数和方法来操作张量，包括改变形状，获取元素、拼接和拆分等。这些操作通常不会改变底层的存储，而是返回一个新的张量视图，这个视图指向相同的数据但是可能有不同的形状或索引方式。
总的来说，张量的存储实现是 PyTorch 能够高效进行张量运算的关键。通过管理一块连续的内存空间，并提供了丰富的操作方法，使得用户可以方便地对多维数组进行各种计算和变换。
