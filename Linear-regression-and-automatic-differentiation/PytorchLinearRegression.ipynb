{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da4520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np  # nn åŒ…å«å„ç§ç¥ç»ç½‘ç»œå±‚ï¼ˆLinearã€Convã€RNN ç­‰ï¼‰å’ŒæŸå¤±å‡½æ•°\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6466e",
   "metadata": {},
   "source": [
    "![1764036997836](image/test/1764036997836.png)\n",
    "![1764037018628](image/test/1764037018628.png)\n",
    "![1764037360899](image/test/1764037360899.png)\n",
    "![1764038482418](image/test/1764038482418.png)\n",
    "![1764038495896](image/test/1764038495896.png)\n",
    "![1764038512298](image/test/1764038512298.png)\n",
    "![1764038528903](image/test/1764038528903.png)\n",
    "![1764038548073](image/test/1764038548073.png)\n",
    "![1764038572779](image/test/1764038572779.png)\n",
    "![1764038585357](image/test/1764038585357.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18a3d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: tensor([-0.5000,  1.8000,  0.9000,  0.4000, -1.4000, -1.4000, -1.8000,  1.5000,\n",
      "         0.4000,  0.8000])\n",
      "epoch: 1, loss = 2921.7229\n",
      "epoch: 10, loss = 1760.0590\n",
      "epoch: 20, loss = 1014.3947\n",
      "epoch: 30, loss = 595.5236\n",
      "epoch: 40, loss = 359.1865\n",
      "epoch: 50, loss = 225.1584\n",
      "epoch: 60, loss = 148.7064\n",
      "epoch: 70, loss = 104.8085\n",
      "epoch: 80, loss = 79.4169\n",
      "epoch: 90, loss = 64.6107\n",
      "epoch: 100, loss = 55.9012\n",
      "epoch: 110, loss = 50.7300\n",
      "epoch: 120, loss = 47.6299\n",
      "epoch: 130, loss = 45.7527\n",
      "epoch: 140, loss = 44.6047\n",
      "epoch: 150, loss = 43.8957\n",
      "epoch: 160, loss = 43.4537\n",
      "epoch: 170, loss = 43.1756\n",
      "epoch: 180, loss = 42.9992\n",
      "epoch: 190, loss = 42.8864\n",
      "epoch: 200, loss = 42.8138\n",
      "epoch: 210, loss = 42.7668\n",
      "epoch: 220, loss = 42.7362\n",
      "epoch: 230, loss = 42.7162\n",
      "epoch: 240, loss = 42.7031\n",
      "epoch: 250, loss = 42.6945\n",
      "epoch: 260, loss = 42.6887\n",
      "epoch: 270, loss = 42.6849\n",
      "epoch: 280, loss = 42.6824\n",
      "epoch: 290, loss = 42.6807\n",
      "epoch: 300, loss = 42.6796\n",
      "epoch: 310, loss = 42.6789\n",
      "epoch: 320, loss = 42.6784\n",
      "epoch: 330, loss = 42.6780\n",
      "epoch: 340, loss = 42.6778\n",
      "epoch: 350, loss = 42.6777\n",
      "epoch: 360, loss = 42.6776\n",
      "epoch: 370, loss = 42.6775\n",
      "epoch: 380, loss = 42.6775\n",
      "epoch: 390, loss = 42.6774\n",
      "epoch: 400, loss = 42.6774\n",
      "epoch: 410, loss = 42.6774\n",
      "epoch: 420, loss = 42.6774\n",
      "epoch: 430, loss = 42.6774\n",
      "epoch: 440, loss = 42.6774\n",
      "epoch: 450, loss = 42.6774\n",
      "epoch: 460, loss = 42.6774\n",
      "epoch: 470, loss = 42.6774\n",
      "epoch: 480, loss = 42.6774\n",
      "epoch: 490, loss = 42.6774\n",
      "epoch: 500, loss = 42.6774\n",
      "epoch: 510, loss = 42.6774\n",
      "epoch: 520, loss = 42.6774\n",
      "epoch: 530, loss = 42.6774\n",
      "epoch: 540, loss = 42.6774\n",
      "epoch: 550, loss = 42.6774\n",
      "epoch: 560, loss = 42.6774\n",
      "epoch: 570, loss = 42.6774\n",
      "epoch: 580, loss = 42.6774\n",
      "epoch: 590, loss = 42.6774\n",
      "epoch: 600, loss = 42.6774\n",
      "epoch: 610, loss = 42.6774\n",
      "epoch: 620, loss = 42.6774\n",
      "epoch: 630, loss = 42.6774\n",
      "epoch: 640, loss = 42.6774\n",
      "epoch: 650, loss = 42.6774\n",
      "epoch: 660, loss = 42.6774\n",
      "epoch: 670, loss = 42.6774\n",
      "epoch: 680, loss = 42.6774\n",
      "epoch: 690, loss = 42.6774\n",
      "epoch: 700, loss = 42.6774\n",
      "epoch: 710, loss = 42.6774\n",
      "epoch: 720, loss = 42.6774\n",
      "epoch: 730, loss = 42.6774\n",
      "epoch: 740, loss = 42.6774\n",
      "epoch: 750, loss = 42.6774\n",
      "epoch: 760, loss = 42.6774\n",
      "epoch: 770, loss = 42.6774\n",
      "epoch: 780, loss = 42.6774\n",
      "epoch: 790, loss = 42.6774\n",
      "epoch: 800, loss = 42.6774\n",
      "epoch: 810, loss = 42.6774\n",
      "epoch: 820, loss = 42.6774\n",
      "epoch: 830, loss = 42.6774\n",
      "epoch: 840, loss = 42.6774\n",
      "epoch: 850, loss = 42.6774\n",
      "epoch: 860, loss = 42.6774\n",
      "epoch: 870, loss = 42.6774\n",
      "epoch: 880, loss = 42.6774\n",
      "epoch: 890, loss = 42.6774\n",
      "epoch: 900, loss = 42.6774\n",
      "epoch: 910, loss = 42.6774\n",
      "epoch: 920, loss = 42.6774\n",
      "epoch: 930, loss = 42.6774\n",
      "epoch: 940, loss = 42.6774\n",
      "epoch: 950, loss = 42.6774\n",
      "epoch: 960, loss = 42.6774\n",
      "epoch: 970, loss = 42.6774\n",
      "epoch: 980, loss = 42.6774\n",
      "epoch: 990, loss = 42.6774\n",
      "epoch: 1000, loss = 42.6774\n",
      "epoch: 1010, loss = 42.6774\n",
      "epoch: 1020, loss = 42.6774\n",
      "epoch: 1030, loss = 42.6774\n",
      "epoch: 1040, loss = 42.6774\n",
      "epoch: 1050, loss = 42.6774\n",
      "epoch: 1060, loss = 42.6774\n",
      "epoch: 1070, loss = 42.6774\n",
      "epoch: 1080, loss = 42.6774\n",
      "epoch: 1090, loss = 42.6774\n",
      "epoch: 1100, loss = 42.6774\n",
      "epoch: 1110, loss = 42.6774\n",
      "epoch: 1120, loss = 42.6774\n",
      "epoch: 1130, loss = 42.6774\n",
      "epoch: 1140, loss = 42.6774\n",
      "epoch: 1150, loss = 42.6774\n",
      "epoch: 1160, loss = 42.6774\n",
      "epoch: 1170, loss = 42.6774\n",
      "epoch: 1180, loss = 42.6774\n",
      "epoch: 1190, loss = 42.6774\n",
      "epoch: 1200, loss = 42.6774\n",
      "epoch: 1210, loss = 42.6774\n",
      "epoch: 1220, loss = 42.6774\n",
      "epoch: 1230, loss = 42.6774\n",
      "epoch: 1240, loss = 42.6774\n",
      "epoch: 1250, loss = 42.6774\n",
      "epoch: 1260, loss = 42.6774\n",
      "epoch: 1270, loss = 42.6774\n",
      "epoch: 1280, loss = 42.6774\n",
      "epoch: 1290, loss = 42.6774\n",
      "epoch: 1300, loss = 42.6774\n",
      "epoch: 1310, loss = 42.6774\n",
      "epoch: 1320, loss = 42.6774\n",
      "epoch: 1330, loss = 42.6774\n",
      "epoch: 1340, loss = 42.6774\n",
      "epoch: 1350, loss = 42.6774\n",
      "epoch: 1360, loss = 42.6774\n",
      "epoch: 1370, loss = 42.6774\n",
      "epoch: 1380, loss = 42.6774\n",
      "epoch: 1390, loss = 42.6774\n",
      "epoch: 1400, loss = 42.6774\n",
      "epoch: 1410, loss = 42.6774\n",
      "epoch: 1420, loss = 42.6774\n",
      "epoch: 1430, loss = 42.6774\n",
      "epoch: 1440, loss = 42.6774\n",
      "epoch: 1450, loss = 42.6774\n",
      "epoch: 1460, loss = 42.6774\n",
      "epoch: 1470, loss = 42.6774\n",
      "epoch: 1480, loss = 42.6774\n",
      "epoch: 1490, loss = 42.6774\n",
      "epoch: 1500, loss = 42.6774\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # nn åŒ…å«å„ç§ç¥ç»ç½‘ç»œå±‚ï¼ˆLinearã€Convã€RNN ç­‰ï¼‰å’ŒæŸå¤±å‡½æ•°\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 1. æ•°æ®å‡†å¤‡ï¼šå°†æ•£ç‚¹æ•°æ®è½¬æˆ Tensor\n",
    "# -----------------------------------------------\n",
    "\n",
    "# åŸå§‹è¾“å…¥æ•°æ®ï¼Œæ¯ä¸€é¡¹æ˜¯ [x, y]\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "\n",
    "# è½¬æˆ NumPy æ•°ç»„ï¼Œæ–¹ä¾¿åˆ‡ç‰‡\n",
    "data = np.array(data)\n",
    "\n",
    "# data[:,0] å–æ‰€æœ‰è¡Œçš„ç¬¬ 0 åˆ— â†’ x\n",
    "# data[:,1] å–æ‰€æœ‰è¡Œçš„ç¬¬ 1 åˆ— â†’ y\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# è½¬æˆ PyTorch çš„ Tensor\n",
    "# dtype=torch.float32 æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒå¿…é¡»çš„æ•°æ®ç±»å‹ï¼ˆé»˜è®¤æ˜¯ float64 ä¼šæŠ¥é”™ï¼‰\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "print(\"x_train:\", x_train)\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2. å®šä¹‰æ¨¡å‹ + æŸå¤±å‡½æ•°\n",
    "# -----------------------------------------------\n",
    "\n",
    "# nn.MSELoss ç”¨äºå›å½’ä»»åŠ¡\n",
    "# MSEï¼ˆMean Squared Errorï¼‰ = å‡æ–¹è¯¯å·®\n",
    "# loss = mean( (y_pred - y_true)^2 )\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ä½¿ç”¨ nn.Sequential å®šä¹‰å‰å‘æ¨¡å‹\n",
    "# Sequential æ˜¯ä¸€ä¸ªâ€œå®¹å™¨â€ï¼Œä¼šæŒ‰ç…§é¡ºåºæ‰§è¡Œé‡Œé¢çš„å±‚\n",
    "# è¿™é‡Œæ”¾å…¥ä¸€ä¸ª nn.Linear(1,1)\n",
    "# nn.Linear(in_features, out_features)\n",
    "# ä½œç”¨ï¼šy = w*x + bï¼ˆçº¿æ€§å›å½’å…¬å¼ï¼‰\n",
    "model = nn.Sequential(  # å®šä¹‰äº†ä¸€ä¸ªâ€œæ¨¡å‹ç®¡é“ï¼ˆSequentialï¼‰\n",
    "    nn.Linear(\n",
    "        1,\n",
    "        1,\n",
    "    ),  # è¾“å…¥ 1 ç»´ â†’ è¾“å‡º 1 ç»´\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3. å®šä¹‰ä¼˜åŒ–å™¨\n",
    "# -----------------------------------------------\n",
    "\n",
    "# torch.optim.SGD ä»£è¡¨éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨\n",
    "# å‚æ•°ï¼š\n",
    "#   - model.parameters() è·å–æ¨¡å‹ä¸­çš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆw å’Œ bï¼‰\n",
    "#   - lr å­¦ä¹ ç‡ï¼ˆå½±å“æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿å¤§å°ï¼‰\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),  # è·å–æ¨¡å‹ä¸­çš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆw å’Œ bï¼‰\n",
    "    lr=0.01,  # è§„å®šäº†ä½¿ç”¨optimizer.step()è¿­ä»£å‚æ•°æ—¶çš„å­¦ä¹ ç‡\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4. è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒè®­ç»ƒé€»è¾‘ï¼‰\n",
    "# -----------------------------------------------\n",
    "\n",
    "epoches = 1500\n",
    "# æ¨¡å‹å¾ªç¯è¿­ä»£åˆ°ä¸€å®šç¨‹åº¦åæ¢¯åº¦ä¼šé™ä¸º0ï¼Œ\n",
    "# æ­¤æ—¶æŸå¤±å€¼å°±ä¸ä¼šå†å‘ç”Ÿå˜åŒ–ã€‚ä¼˜åŒ–ç¨‹åº¦ä¹Ÿåˆ°è¾¾äº†æ¨¡å‹å®šä¹‰çš„æé™\n",
    "\n",
    "for n in range(1, epoches + 1):\n",
    "\n",
    "    # x_train å½¢çŠ¶æ˜¯ (10,)\n",
    "    # ç¥ç»ç½‘ç»œè¦æ±‚äºŒç»´è¾“å…¥ï¼š(æ ·æœ¬æ•°, ç‰¹å¾æ•°)\n",
    "    # unsqueeze(1) çš„ä½œç”¨æ˜¯åœ¨ç¬¬ 1 ç»´æ’å…¥ä¸€ä¸ªç»´åº¦ â†’ (10,1)\n",
    "    # åŸæœ¬ï¼štensor([1.0, 2.0, 3.0]) â†’ unsqueeze(1) â†’ tensor([[1.0],[2.0],[3.0]])\n",
    "    # åœ¨æŒ‡å®šä½ç½®æ’å…¥ä¸€ä¸ªæ–°çš„ç»´åº¦ï¼ˆå¤§å°ä¸º 1ï¼‰ã€‚ï¼ï¼ï¼ï¼ æ³¨æ„æ˜¯å†æŒ‡å®šä½ç½®ï¼Œä¼ å…¥çš„å‚æ•°æ˜¯è§„å®šçš„æ’å…¥ç»´åº¦çš„ä½ç½®\n",
    "    x_input = x_train.unsqueeze(1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­ï¼ˆè®¡ç®—é¢„æµ‹å€¼ï¼‰\n",
    "    # ç›¸å½“äºï¼šy_pred = w*x + b\n",
    "    y_pred = model(x_input)\n",
    "\n",
    "    # y_pred å½¢çŠ¶æ˜¯ (10,1)ï¼Œä½† y_train æ˜¯ (10,)\n",
    "    # squeeze(1) ç”¨æ¥å»æ‰å¤šä½™çš„ç»´åº¦ï¼Œä½¿ä¸¤è€…å½¢çŠ¶ä¸€è‡´\n",
    "    loss = criterion(\n",
    "        y_pred.squeeze(1),\n",
    "        y_train,\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # ä¸‹é¢ä¸‰æ­¥æ˜¯å›ºå®šæµç¨‹ï¼ˆå¿…é¡»è¿™ä¹ˆå†™ï¼‰\n",
    "    # ------------------------------\n",
    "\n",
    "    # Step 1ï¼šæ¸…ç©ºä¹‹å‰è®¡ç®—çš„æ¢¯åº¦\n",
    "    # å› ä¸º PyTorch çš„æ¢¯åº¦ä¼šè‡ªåŠ¨ç´¯åŠ ï¼Œä¸æ¸…ç©ºä¼šå½±å“ä¸‹ä¸€æ¬¡æ›´æ–°\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Step 2ï¼šåå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "    # loss.backward() = è‡ªåŠ¨æ±‚ âˆ‚loss/âˆ‚wã€âˆ‚loss/âˆ‚b\n",
    "    loss.backward()\n",
    "\n",
    "    # Step 3ï¼šä¼˜åŒ–å™¨æ›´æ–°å‚æ•°\n",
    "    # w = w - lr * w.grad\n",
    "    # b = b - lr * b.grad\n",
    "    optimizer.step()\n",
    "\n",
    "    # æ¯ 10 æ¬¡æ‰“å°ä¸€æ¬¡æŸå¤±å€¼\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoch: {n}, loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bcd77",
   "metadata": {},
   "source": [
    "![1764041272136](image/test/1764041272136.png)\n",
    "![1764041431791](image/test/1764041431791.png)\n",
    "![1764041494811](image/test/1764041494811.png)\n",
    "![1764041620588](image/test/1764041620588.png)\n",
    "![1764041716371](image/test/1764041716371.png)\n",
    "![1764041884246](image/test/1764041884246.png)\n",
    "![1764041890930](image/test/1764041890930.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6ccea",
   "metadata": {},
   "source": [
    "| å®¹å™¨              | èƒ½ä¸èƒ½è‡ªåŠ¨æ³¨å†Œå‚æ•°ï¼Ÿ | èƒ½ä¸èƒ½è‡ªåŠ¨æ‰§è¡Œ forwardï¼Ÿ     | èƒ½ä¸èƒ½æŒ‰åå­—è®¿é—®ï¼Ÿ | ä½¿ç”¨åœºæ™¯                     | æœ¬è´¨             |\n",
    "| ----------------- | -------------------- | ---------------------------- | ------------------ | ---------------------------- | ---------------- |\n",
    "| **nn.Sequential** | âœ” èƒ½                 | âœ” èƒ½ï¼ˆæŒ‰é¡ºåºè‡ªåŠ¨ forwardï¼‰   | âœ˜ ä¸èƒ½             | é¡ºåºç½‘ç»œï¼ˆæŒ‰ pipeline æ‰§è¡Œï¼‰ | â€œç½‘ç»œæµæ°´çº¿â€     |\n",
    "| **nn.ModuleList** | âœ” èƒ½                 | âœ˜ ä¸èƒ½ï¼ˆéœ€è¦è‡ªå·±å†™ forwardï¼‰ | âœ˜ ä¸èƒ½             | å¯å˜å±‚ã€å¾ªç¯æ„å»ºç½‘ç»œ         | â€œå¯è®­ç»ƒå±‚çš„åˆ—è¡¨â€ |\n",
    "| **nn.ModuleDict** | âœ” èƒ½                 | âœ˜ ä¸èƒ½ï¼ˆéœ€è¦è‡ªå·±å†™ forwardï¼‰ | âœ” èƒ½ï¼ˆå­—å…¸ç»“æ„ï¼‰   | ç”¨åå­—ç®¡ç†å¤šä¸ªå­æ¨¡å—         | â€œå¯è®­ç»ƒå±‚çš„å­—å…¸â€ |\n",
    "\n",
    "```lua\n",
    "\n",
    "             y = model(x)\n",
    "                    â”‚\n",
    "                    â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚ nn.Module.__call__  â”‚   â† ä½ æ²¡æœ‰çœ‹åˆ°ï¼Œä½†æ­¤æ—¶åœ¨è¿è¡Œ\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â”‚\n",
    "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "     â”‚              â”‚                          â”‚\n",
    "     â–¼              â–¼                          â–¼\n",
    "è§¦å‘ forward     Dropout/BN æ§åˆ¶            è‡ªåŠ¨æ±‚å¯¼å›¾æ„å»º\n",
    "pre-hooks        ï¼ˆtrain/eval åŒºåˆ«ï¼‰         ï¼ˆAutogradï¼‰\n",
    "                    â”‚\n",
    "                    â–¼\n",
    "           è°ƒç”¨ forward(x)\n",
    "                    â”‚\n",
    "                    â–¼\n",
    "       å¾—åˆ°è¾“å‡ºå¼ é‡ output\n",
    "                    â”‚\n",
    "                    â–¼\n",
    "        è§¦å‘ forward post-hooks\n",
    "                    â”‚\n",
    "                    â–¼\n",
    "             è¿”å› output\n",
    "\n",
    "```\n",
    "\n",
    "![1764054694159](image/test/1764054694159.png)\n",
    "\n",
    "# ğŸ”¥ ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥è°ƒç”¨ forwardï¼Ÿï¼ˆéå¸¸éå¸¸å…³é”®ï¼‰\n",
    "\n",
    "| æœºåˆ¶                      | model(x) | model.forward(x) |\n",
    "| ------------------------- | -------- | ---------------- |\n",
    "| è‡ªåŠ¨æ±‚å¯¼å›¾æ„å»º            | âœ” æœ‰     | âŒ æ²¡æœ‰          |\n",
    "| Dropout è®­ç»ƒ/æ¨ç†æ¨¡å¼æ§åˆ¶ | âœ” æœ‰     | âŒ æ²¡æœ‰          |\n",
    "| BatchNorm çŠ¶æ€æ›´æ–°        | âœ” æœ‰     | âŒ æ²¡æœ‰          |\n",
    "| Forward pre/post hooks    | âœ” æœ‰     | âŒ æ²¡æœ‰          |\n",
    "| è°ƒè¯•ã€è¿½è¸ªã€é‡åŒ–æµç¨‹      | âœ” æœ‰     | âŒ éƒ½ä¼šå¤±æ•ˆ      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eba881",
   "metadata": {},
   "source": [
    "## â‘¡ æ ¹æ®è®­ç»ƒæ¨¡å¼/è¯„ä¼°æ¨¡å¼å¤„ç† Dropout / BatchNorm\n",
    "\n",
    "- PyTorch çš„ model æœ‰ä¸¤ç§æ¨¡å¼ï¼š\n",
    "\n",
    "  - `model.train()`ï¼šè®­ç»ƒæ¨¡å¼\n",
    "  - `model.eval()`ï¼šè¯„ä¼°/æ¨ç†æ¨¡å¼\n",
    "\n",
    "- è¿™ä¸¤ç§æ¨¡å¼ä¸ä»…æ˜¯â€œä¸€ä¸ªæ ‡è®°â€ï¼Œå®ƒä¼šç›´æ¥å½±å“æŸäº›ç‰¹æ®Šå±‚çš„è¡Œä¸ºï¼š\n",
    "\n",
    "### Dropoutï¼š\n",
    "\n",
    "- åœ¨ `train()` æ¨¡å¼ï¼šä¼šéšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼ˆä¾‹å¦‚ [a,b,c,d] â†’ [a,0,c,0]ï¼‰\n",
    "- åœ¨ `eval()` æ¨¡å¼ï¼šä¸ä¼šä¸¢å¼ƒä»»ä½•ç¥ç»å…ƒï¼ˆä¿æŒç¨³å®šè¾“å‡ºï¼‰\n",
    "- è‹¥ä½¿ç”¨ `forward()` ç›´æ¥è°ƒç”¨ï¼ŒDropout å°†ä¸ä¼šæ­£ç¡®åˆ‡æ¢æ¨¡å¼\n",
    "\n",
    "### BatchNormï¼š\n",
    "\n",
    "- åœ¨ `train()` æ¨¡å¼ï¼šä½¿ç”¨å½“å‰ batch çš„å‡å€¼/æ–¹å·®ï¼Œå¹¶æ›´æ–° running_mean / running_var\n",
    "- åœ¨ `eval()` æ¨¡å¼ï¼šä½¿ç”¨è®­ç»ƒæ—¶è®°å½•ä¸‹æ¥çš„ running_mean / running_varï¼Œä¸ä½¿ç”¨å½“å‰ batch çš„ç»Ÿè®¡å€¼\n",
    "- è‹¥ä½¿ç”¨ `forward()` ç›´æ¥è°ƒç”¨ï¼ŒBatchNorm ä¹Ÿä¼šè·³è¿‡ç»Ÿè®¡æ›´æ–°é€»è¾‘\n",
    "\n",
    "**é‡è¦ï¼š**\n",
    "\n",
    "- Dropout / BatchNorm çš„æ¨¡å¼åˆ‡æ¢é€»è¾‘ä¸åœ¨ `forward()` ä¸­ï¼Œè€Œåœ¨ `nn.Module.__call__()` ä¸­å®ç°\n",
    "- å› æ­¤ä¸èƒ½ç›´æ¥ç”¨ `model.forward(x)`ï¼Œå¿…é¡»ä½¿ç”¨ `model(x)` æ¥ä¿è¯æ¨¡å¼æ­£ç¡®åˆ‡æ¢\n",
    "\n",
    "## â‘£ forward hooksï¼ˆå‰å‘é’©å­ï¼‰æœºåˆ¶\n",
    "\n",
    "PyTorch æ”¯æŒåœ¨ forward å‰åæŒ‚é’©å­å‡½æ•°ï¼ˆhookï¼‰ï¼Œç”¨äºï¼š\n",
    "\n",
    "- æ•è·ä¸­é—´ç‰¹å¾\n",
    "- è°ƒè¯•æ¨¡å‹\n",
    "- å¯è§†åŒ–ç‰¹å¾\n",
    "- ä¿®æ”¹è¾“å…¥/è¾“å‡º\n",
    "- å®ç°å¤æ‚ç½‘ç»œé€»è¾‘ï¼ˆå¦‚ç‰¹å¾èåˆï¼‰\n",
    "\n",
    "### forward pre-hookï¼ˆå‰ç½®é’©å­ï¼‰\n",
    "\n",
    "- åœ¨ `forward()` æ‰§è¡Œä¹‹å‰è§¦å‘\n",
    "- å¸¸ç”¨äºæŸ¥çœ‹è¾“å…¥æˆ–ä¿®æ”¹è¾“å…¥ï¼š\n",
    "  ```python\n",
    "  model.register_forward_pre_hook(hook_fn)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ **æœ€ç»ˆä¸€å¥æ€»ç»“ï¼ˆä¹Ÿé€‚åˆæ”¾è¿›ä½ çš„ç¬”è®°ï¼‰**\n",
    "\n",
    "\n",
    "- `model(x)` ä¼šè§¦å‘ï¼š\n",
    "\n",
    "  - Dropout/BatchNorm çš„è®­ç»ƒ/æ¨ç†æ¨¡å¼æ§åˆ¶\n",
    "  - forward pre-hooks & forward post-hooks\n",
    "  - è‡ªåŠ¨æ±‚å¯¼è®¡ç®—å›¾æ„å»º\n",
    "  - è°ƒè¯•ä¸é‡åŒ–å·¥å…·ä¾èµ–çš„ forward è°ƒåº¦é€»è¾‘\n",
    "\n",
    "- `model.forward(x)` åªæ‰§è¡Œä½ å†™çš„æ•°å­¦è¿ç®—ï¼Œä¸åŒ…å« PyTorch æ‰€æœ‰æ¡†æ¶çº§åŠŸèƒ½\n",
    "\n",
    "=> åªèƒ½ç”¨ model(x)ï¼Œä¸èƒ½ç”¨ model.forward(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15796d40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      5\u001b[39m data = [\n\u001b[32m      6\u001b[39m     [-\u001b[32m0.5\u001b[39m, \u001b[32m7.7\u001b[39m],\n\u001b[32m      7\u001b[39m     [\u001b[32m1.8\u001b[39m, \u001b[32m98.5\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     [\u001b[32m0.8\u001b[39m, \u001b[32m62.3\u001b[39m],\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# è½¬æ¢ä¸º NumPy æ•°ç»„\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m data = \u001b[43mnp\u001b[49m.array(data)  \u001b[38;5;66;03m# ç›®çš„æ˜¯ä¸ºäº†æ–¹ä¾¿åˆ‡ç‰‡è®¿é—®\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# æå– x_data å’Œ y_data\u001b[39;00m\n\u001b[32m     20\u001b[39m x_data = data[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"æ¨¡å‹å®šä¹‰MoudleList\"\"\"\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)  # ç›®çš„æ˜¯ä¸ºäº†æ–¹ä¾¿åˆ‡ç‰‡è®¿é—®\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œ y_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)  # pytorchä¸­å¿…é¡»ä½¿ç”¨32ä½\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)  # pytorchä¸­å¿…é¡»ä½¿ç”¨32ä½\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "# å®šä¹‰æŸå¤±å‡½æ•°\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ2ï¼š\n",
    "# nn.ModuleList() å’Œ pythonçš„åŸºç¡€æ•°æ®ç±»å‹listç±»ä¼¼ï¼Œä¸æŒ‰ç…§é¡ºåºï¼Œæ²¡æœ‰forwardæ–¹æ³•ï¼Œ\n",
    "# ä¸å¯ä»¥å®šä¹‰åå­—ï¼Œå¯ä»¥ç”¨appendåŠ ç½‘ç»œã€‚\n",
    "# å¦‚æœä½¿ç”¨éœ€è¦é‡å†™ç»§æ‰¿nn.Module\n",
    "# æ˜¾ç¤ºå®šä¹‰LinerModelç±»\n",
    "class LinerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # è¿™æ˜¯Python2ä¸­çš„å†™æ³•\n",
    "        # Python3ä¸­è¿™ä¹ˆå†™super().__init__()\n",
    "        super(\n",
    "            LinerModel, self\n",
    "        ).__init__()  # è°ƒç”¨çˆ¶ç±»ï¼ˆnn.Moduleï¼‰çš„æ„é€ å‡½æ•° __init__() # è°ƒç”¨çˆ¶ç±» nn.Module çš„åˆå§‹åŒ–ï¼Œå¯ç”¨è‡ªåŠ¨æ³¨å†Œå­æ¨¡å—ã€è‡ªåŠ¨æ±‚å¯¼ç­‰æ ¸å¿ƒæœºåˆ¶\n",
    "        # ç½‘ç»œå±‚å­˜å…¥åˆ°nn.ModuleList\n",
    "        self.layers = nn.ModuleList(  # å­æ¨¡å—ä¼šè¢«è‡ªåŠ¨æ³¨å†Œï¼ˆåŠ å…¥åˆ° model.parameters()\n",
    "            [\n",
    "                nn.Linear(1, 1),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x  # å®šä¹‰å‰å‘ä¼ æ’­è®¡ç®—å›¾ï¼ˆä¸å¤„ç†è®­ç»ƒæ¨¡å¼/æ¨ç†æ¨¡å¼é€»è¾‘ï¼‰\n",
    "\n",
    "\n",
    "model = LinerModel()\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# å¼€å§‹è¿­ä»£\n",
    "epoches = 500\n",
    "for n in range(1, epoches + 1):\n",
    "    # ç°åœ¨x_train ç›¸å½“äº10ä¸ªæ ·æœ¬ï¼Œä½†æ˜¯ç°åœ¨ç»´åº¦ï¼Œæ·»åŠ ä¸€ä¸ªç»´åº¦\n",
    "    # 10x1   å˜æˆæ ·æœ¬ x ç»´åº¦å½¢å¼\n",
    "    # ---------------------------------------------------------\n",
    "    # ---------------------------------------------------------\n",
    "    # å…³é”®ç‚¹ï¼šä¸ºä»€ä¹ˆ model(x) èƒ½ç›´æ¥è¿è¡Œï¼Ÿ\n",
    "    # ---------------------------------------------------------\n",
    "    # ---------------------------------------------------------\n",
    "    # å› ä¸º PyTorch åœ¨ nn.Module ä¸­é‡å†™äº† __call__ æ–¹æ³•ã€‚\n",
    "    # ä½ å†™ model(x)ï¼Œå®é™…ä¸Šè°ƒç”¨çš„æ˜¯ model.__call__(x)\n",
    "    # __call__ å†…éƒ¨ä¼šï¼š\n",
    "    #   â‘  å¤„ç† hooksï¼ˆforward pre-hooksï¼‰\n",
    "    #   â‘¡ æ ¹æ®è®­ç»ƒæ¨¡å¼/è¯„ä¼°æ¨¡å¼å¤„ç† Dropout / BatchNorm\n",
    "    #   â‘¢ è°ƒç”¨ forward(x)ï¼ˆä½ è‡ªå·±å®šä¹‰çš„å‰å‘é€»è¾‘ï¼‰\n",
    "    #   â‘£ å¤„ç† hooksï¼ˆforward post-hooksï¼‰\n",
    "    #   â‘¤ æ„å»º autograd è®¡ç®—å›¾ï¼ˆåªæœ‰ __call__ æ‰ä¼šåˆ›å»ºè®¡ç®—å›¾ï¼‰\n",
    "    # å› æ­¤ï¼šä¸è¦æ‰‹åŠ¨è°ƒç”¨ forwardï¼Œå¦åˆ™ä¼šè·³è¿‡è¿™äº›æœºåˆ¶ã€‚\n",
    "    y_prd = model(x_train.unsqueeze(1))  ################### 1.å‰å‘ä¼ æ’­\n",
    "    # è®¡ç®—æŸå¤±\n",
    "    # y_prdåœ¨å‰é¢ï¼Œy_true æ˜¯åé¢\n",
    "    loss = criterion(y_prd.squeeze(1), y_train)  ########### 2.æŸå¤±å‡½æ•°\n",
    "    # æ¢¯åº¦æ›´æ–°\n",
    "    # æ¸…ç©ºä¹‹å‰å­˜å‚¨åœ¨ä¼˜åŒ–å™¨ä¸­çš„æ¢¯åº¦\n",
    "    optimizer.zero_grad()  ################################# 3.æ¢¯åº¦ä¸‹é™\n",
    "    # æŸå¤±å‡½æ•°å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦\n",
    "    loss.backward()  ####################################### 4.åå‘ä¼ æ’­\n",
    "    # æ ¹æ®ä¼˜åŒ–ç®—æ³•æ›´æ–°å‚æ•°\n",
    "    optimizer.step()  ###################################### 5.å‚æ•°ä¼˜åŒ–\n",
    "    # 5ã€æ˜¾ç¤ºé¢‘ç‡è®¾ç½®\n",
    "    # ä¸å…ˆç”»å›¾\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoches:{n},loss:{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eeccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5000,  1.8000,  0.9000,  0.4000, -1.4000, -1.4000, -1.8000,  1.5000,\n",
      "         0.4000,  0.8000])\n",
      "self.layers_dict Linear\n",
      "epoches:1, loss:2886.514892578125\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:10, loss:1739.3502197265625\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:20, loss:1002.8888549804688\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:30, loss:589.1149291992188\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:40, loss:355.60638427734375\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:50, loss:223.1516571044922\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:60, loss:147.57687377929688\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:70, loss:104.16978454589844\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:80, loss:79.05378723144531\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:90, loss:64.40296173095703\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:100, loss:55.78143310546875\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:110, loss:50.6605110168457\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:120, loss:47.589168548583984\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:130, loss:45.72867965698242\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:140, loss:44.590370178222656\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:150, loss:43.887062072753906\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:160, loss:43.448394775390625\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:170, loss:43.172340393066406\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:180, loss:42.997161865234375\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:190, loss:42.88515853881836\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:200, loss:42.81303787231445\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:210, loss:42.76633834838867\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:220, loss:42.735931396484375\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:230, loss:42.716033935546875\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:240, loss:42.70296096801758\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:250, loss:42.6943473815918\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:260, loss:42.68866729736328\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:270, loss:42.68489456176758\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:280, loss:42.6823844909668\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:290, loss:42.68070602416992\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:300, loss:42.67960739135742\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:310, loss:42.678855895996094\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:320, loss:42.67837142944336\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:330, loss:42.67803955078125\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:340, loss:42.677818298339844\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:350, loss:42.677669525146484\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:360, loss:42.677574157714844\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:370, loss:42.677513122558594\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:380, loss:42.677467346191406\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:390, loss:42.67742919921875\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:400, loss:42.67741775512695\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:410, loss:42.677406311035156\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:420, loss:42.67740249633789\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:430, loss:42.67738723754883\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:440, loss:42.6773796081543\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:450, loss:42.67737579345703\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:460, loss:42.67737579345703\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:470, loss:42.67737579345703\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:480, loss:42.67738342285156\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:490, loss:42.677371978759766\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "self.layers_dict Linear\n",
      "epoches:500, loss:42.67737579345703\n"
     ]
    }
   ],
   "source": [
    "\"\"\"æ¨¡å‹å®šä¹‰ MoudleDict\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. æ•£ç‚¹æ•°æ®å‡†å¤‡\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# è¾“å…¥æ•°æ®ï¼ˆæ¯æ¡æ˜¯ [x, y]ï¼‰\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "\n",
    "# è½¬ä¸º NumPy æ•°ç»„ï¼Œä¾¿äºåˆ‡ç‰‡\n",
    "data = np.array(data)  # shape: (10, 2)\n",
    "\n",
    "# å–å‡ºè¾“å…¥ä¸è¾“å‡º\n",
    "x_data = data[:, 0]  # æ‰€æœ‰è¡Œçš„ç¬¬ 0 åˆ—\n",
    "y_data = data[:, 1]  # æ‰€æœ‰è¡Œçš„ç¬¬ 1 åˆ—\n",
    "\n",
    "# è½¬ä¸º PyTorch tensorï¼ˆå¿…é¡»ä½¿ç”¨ float32ï¼‰\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)  # shape: (10,)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)  # shape: (10,)\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆMSEï¼šå‡æ–¹è¯¯å·®ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "criterion = nn.MSELoss()  # å›å½’ä»»åŠ¡æœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. å®šä¹‰ç½‘ç»œæ¨¡å‹ï¼ˆä½¿ç”¨ nn.ModuleDictï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "# nn.ModuleDict ä¸ Python çš„ dict ç±»ä¼¼ï¼š\n",
    "# - key æ˜¯å­—ç¬¦ä¸²ï¼Œä»£è¡¨å­æ¨¡å—çš„åç§°\n",
    "# - value å¿…é¡»æ˜¯ nn.Module å­ç±»ï¼ˆå¦‚ Linearï¼‰\n",
    "# - å­æ¨¡å—ä¼šè¢«è‡ªåŠ¨æ³¨å†Œåˆ°æ¨¡å‹ä¸­ï¼ˆèƒ½è¢« optimizer æ‰¾åˆ°å‚æ•°ï¼‰\n",
    "# - æ²¡æœ‰ forward æ–¹æ³•ï¼Œéœ€è¦è‡ªå·±é‡å†™ forward\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # super(\n",
    "        #     LinearModel, self\n",
    "        # ).__init__()  # åˆå§‹åŒ– nn.Moduleï¼ˆæ³¨å†Œæ¨¡å—ã€å¯ç”¨ autograd ç­‰ï¼‰\n",
    "        super().__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ª ModuleDictï¼Œç”¨ key ä¿å­˜æ¨¡å—\n",
    "        self.layers_dict = nn.ModuleDict(\n",
    "            {\n",
    "                \"Linear\": nn.Linear(\n",
    "                    1, 1\n",
    "                ),  # key=\"Linear\"ï¼Œvalue=çº¿æ€§å±‚ï¼ˆè¾“å…¥1ç»´â†’è¾“å‡º1ç»´ï¼‰\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleDict ä¸ä¿è¯é¡ºåºï¼Œä½† key é¡ºåºå¯éå†\n",
    "        for key in self.layers_dict:\n",
    "            print(\"self.layers_dict\", key)\n",
    "            x = self.layers_dict[key](x)  # æŒ‰ key å–å‡ºå­æ¨¡å—æ‰§è¡Œ forward\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹ï¼ˆåˆ›å»ºæƒé‡å‚æ•° wã€bï¼‰\n",
    "model = LinearModel()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. å®šä¹‰ä¼˜åŒ–å™¨ï¼ˆSGDï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),  # ä¼ å…¥æ¨¡å‹çš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆè‡ªåŠ¨æ”¶é›†ï¼‰\n",
    "    lr=0.01,  # å­¦ä¹ ç‡ï¼šæ§åˆ¶æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒè®­ç»ƒé€»è¾‘ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "epoches = 500\n",
    "\n",
    "for n in range(1, epoches + 1):\n",
    "\n",
    "    # x_train åŸå§‹ shape æ˜¯ (10,)\n",
    "    # unsqueeze(1) æ’å…¥ç»´åº¦ â†’ å˜æˆ (10,1)ï¼Œç¬¦åˆ Linear è¾“å…¥æ ¼å¼ (batch, features)\n",
    "    x_input = x_train.unsqueeze(1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­ï¼ˆå®é™…è°ƒç”¨çš„æ˜¯ model.__call__ â†’ è‡ªåŠ¨è§¦å‘ hooks + è‡ªåŠ¨æ±‚å¯¼ï¼‰\n",
    "    y_prd = model(x_input)  # è¾“å‡º shape: (10,1)\n",
    "\n",
    "    # å»æ‰å¤šä½™çš„ç»´åº¦ï¼Œä½¿ shape ä¸ y_train å¯¹é½\n",
    "    loss = criterion(\n",
    "        y_prd.squeeze(1),  # y_prd: (10,1) â†’ (10,)\n",
    "        y_train,  # y_train: (10,)\n",
    "    )\n",
    "\n",
    "    # æ¢¯åº¦æ›´æ–°æµç¨‹ï¼ˆå›ºå®šä¸‰æ­¥ï¼‰\n",
    "\n",
    "    optimizer.zero_grad()  # â‘  æ¸…ç©ºæ—§æ¢¯åº¦ï¼ˆé˜²æ­¢æ¢¯åº¦ç´¯åŠ ï¼‰\n",
    "    loss.backward()  # â‘¡ åå‘ä¼ æ’­ï¼šè‡ªåŠ¨è®¡ç®—å‚æ•°æ¢¯åº¦\n",
    "    optimizer.step()  # â‘¢ å‚æ•°æ›´æ–°ï¼šåŸºäº lr è°ƒæ•´ wã€b\n",
    "\n",
    "    # æ‰“å° loss\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoches:{n}, loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5000,  1.8000,  0.9000,  0.4000, -1.4000, -1.4000, -1.8000,  1.5000,\n",
      "         0.4000,  0.8000])\n",
      "epoches:1, loss:3004.26025390625\n",
      "epoches:10, loss:1811.974609375\n",
      "epoches:20, loss:1045.701904296875\n",
      "epoches:30, loss:614.5923461914062\n",
      "epoches:40, loss:370.91668701171875\n",
      "epoches:50, loss:232.4441375732422\n",
      "epoches:60, loss:153.273193359375\n",
      "epoches:70, loss:107.69586181640625\n",
      "epoches:80, loss:81.25704193115234\n",
      "epoches:90, loss:65.79182434082031\n",
      "epoches:100, loss:56.664154052734375\n",
      "epoches:110, loss:51.2257080078125\n",
      "epoches:120, loss:47.953468322753906\n",
      "epoches:130, loss:45.96489715576172\n",
      "epoches:140, loss:44.74433517456055\n",
      "epoches:150, loss:43.98787307739258\n",
      "epoches:160, loss:43.51466369628906\n",
      "epoches:170, loss:43.216033935546875\n",
      "epoches:180, loss:43.026058197021484\n",
      "epoches:190, loss:42.90431213378906\n",
      "epoches:200, loss:42.825767517089844\n",
      "epoches:210, loss:42.774803161621094\n",
      "epoches:220, loss:42.74156951904297\n",
      "epoches:230, loss:42.71977996826172\n",
      "epoches:240, loss:42.705474853515625\n",
      "epoches:250, loss:42.6960334777832\n",
      "epoches:260, loss:42.68977737426758\n",
      "epoches:270, loss:42.685630798339844\n",
      "epoches:280, loss:42.68286895751953\n",
      "epoches:290, loss:42.681053161621094\n",
      "epoches:300, loss:42.679832458496094\n",
      "epoches:310, loss:42.679012298583984\n",
      "epoches:320, loss:42.678462982177734\n",
      "epoches:330, loss:42.6781120300293\n",
      "epoches:340, loss:42.67786407470703\n",
      "epoches:350, loss:42.67770004272461\n",
      "epoches:360, loss:42.677589416503906\n",
      "epoches:370, loss:42.67750930786133\n",
      "epoches:380, loss:42.677459716796875\n",
      "epoches:390, loss:42.67744064331055\n",
      "epoches:400, loss:42.67741775512695\n",
      "epoches:410, loss:42.67740249633789\n",
      "epoches:420, loss:42.67739486694336\n",
      "epoches:430, loss:42.67738723754883\n",
      "epoches:440, loss:42.67738723754883\n",
      "epoches:450, loss:42.677391052246094\n",
      "epoches:460, loss:42.67738342285156\n",
      "epoches:470, loss:42.67738723754883\n",
      "epoches:480, loss:42.677371978759766\n",
      "epoches:490, loss:42.677391052246094\n",
      "epoches:500, loss:42.6773796081543\n"
     ]
    }
   ],
   "source": [
    "\"\"\"æ¨¡å‹å®šä¹‰ç›´æ¥ç»§æ‰¿nn.Moudle\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. æ•£ç‚¹æ•°æ®å‡†å¤‡\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# è¾“å…¥æ•°æ®ï¼ˆæ¯æ¡æ˜¯ [x, y]ï¼‰\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "\n",
    "# è½¬æˆ NumPy æ•°ç»„ï¼Œä¾¿äºåˆ‡ç‰‡\n",
    "data = np.array(data)  # shape: (10, 2)\n",
    "\n",
    "# æå–è¾“å…¥ x å’Œè¾“å‡º y\n",
    "x_data = data[:, 0]  # æ‰€æœ‰è¡Œçš„ç¬¬0åˆ—\n",
    "y_data = data[:, 1]  # æ‰€æœ‰è¡Œçš„ç¬¬1åˆ—\n",
    "\n",
    "# è½¬æˆ Tensorï¼ˆPyTorch è®­ç»ƒå¿…é¡»ä½¿ç”¨ float32ï¼‰\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)  # shape: (10,)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)  # shape: (10,)\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆMSEï¼šå‡æ–¹è¯¯å·®ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "criterion = nn.MSELoss()  # å¸¸ç”¨äºå›å½’ä»»åŠ¡\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. å®šä¹‰æ¨¡å‹ï¼ˆç»§æ‰¿ nn.Moduleï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(\n",
    "            LinearModel, self\n",
    "        ).__init__()  # è°ƒç”¨ nn.Module åˆå§‹åŒ–ï¼ˆæ³¨å†Œå­æ¨¡å—ã€æ”¯æŒè‡ªåŠ¨æ±‚å¯¼ç­‰ï¼‰\n",
    "\n",
    "        # å®šä¹‰çº¿æ€§å±‚ï¼šè¾“å…¥ 1 ç»´ â†’ è¾“å‡º 1 ç»´\n",
    "        # nn.Linear å†…éƒ¨è‡ªåŠ¨åˆ›å»º w å’Œ bï¼Œå¹¶åŠ å…¥æ¨¡å‹å‚æ•°\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):  # å®šä¹‰å‰å‘ä¼ æ’­\n",
    "        x = self.layers(x)  # è°ƒç”¨çº¿æ€§å±‚ï¼ˆæ‰§è¡Œ y = w*x + bï¼‰\n",
    "        return x  # forward åªè´Ÿè´£æ•°å­¦ï¼Œä¸è´Ÿè´£è‡ªåŠ¨æ±‚å¯¼\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä¼šåˆ›å»ºå‚æ•° wã€bï¼‰\n",
    "model = LinearModel()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. å®šä¹‰ä¼˜åŒ–å™¨ï¼ˆSGDï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),  # ä¼ å…¥æ¨¡å‹ä¸­çš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°ï¼ˆè‡ªåŠ¨æ”¶é›†ï¼‰\n",
    "    lr=0.01,  # å­¦ä¹ ç‡ï¼šæ§åˆ¶æ¯ä¸€æ­¥å‚æ•°æ›´æ–°å¹…åº¦\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒè®­ç»ƒé€»è¾‘ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "epoches = 500  # è®­ç»ƒè½®æ•°\n",
    "\n",
    "for n in range(1, epoches + 1):\n",
    "\n",
    "    # x_train åŸæœ¬ shape ä¸º (10,)\n",
    "    # unsqueeze(1) â†’ æ’å…¥ç¬¬1ç»´ï¼Œä½¿å…¶æˆä¸º (10,1)ï¼Œç¬¦åˆ nn.Linear çš„è¾“å…¥æ ¼å¼\n",
    "    x_input = x_train.unsqueeze(1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­ï¼šé€šè¿‡ __call__() è‡ªåŠ¨æ‰§è¡Œ forward()\n",
    "    y_prd = model(x_input)  # shape: (10,1)\n",
    "\n",
    "    # y_prd shape ä¸º (10,1)ï¼Œè€Œ y_train shape ä¸º (10,)\n",
    "    # squeeze(1) å»æ‰å¤šä½™ç»´åº¦ï¼Œä½¿ shape å¯¹é½\n",
    "    loss = criterion(y_prd.squeeze(1), y_train)\n",
    "\n",
    "    # æ¢¯åº¦æ›´æ–°ä¸‰éƒ¨æ›²ï¼š\n",
    "\n",
    "    optimizer.zero_grad()  # â‘  æ¸…ç©ºæ—§æ¢¯åº¦ï¼ˆPyTorch æ¢¯åº¦é»˜è®¤ç´¯åŠ ï¼‰\n",
    "    loss.backward()  # â‘¡ åå‘ä¼ æ’­ï¼šè‡ªåŠ¨è®¡ç®— âˆ‚loss/âˆ‚wã€âˆ‚loss/âˆ‚b\n",
    "    optimizer.step()  # â‘¢ å‚æ•°æ›´æ–°ï¼šw = w - lr * grad\n",
    "\n",
    "    # æ¯ 10 æ¬¡æ‰“å°ä¸€æ¬¡æŸå¤±\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoches:{n}, loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45676e74",
   "metadata": {},
   "source": [
    "![1764060945241](image/test/1764060945241.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01315769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train tensor([[-0.7888,  0.1581,  0.0567],\n",
      "        [ 1.7314, -0.3567,  0.1782],\n",
      "        [-0.0572, -1.4479, -1.0413],\n",
      "        [ 1.2446, -1.7670,  0.8510],\n",
      "        [-1.0932, -0.0383,  0.7693],\n",
      "        [ 0.5409,  1.5316,  1.1781],\n",
      "        [-0.4854,  0.1737, -0.1337],\n",
      "        [ 0.1622, -1.0616,  0.8330],\n",
      "        [-1.1396, -1.4029, -1.7995],\n",
      "        [-1.0782,  1.8044,  1.1951]])\n",
      "y_train tensor([ 0.2935,  1.1050, -0.6464,  0.6462, -1.7645, -1.0674, -1.5651,  0.6130,\n",
      "        -0.2634,  0.2080])\n",
      "dataset[0] (tensor([-0.7888,  0.1581,  0.0567]), tensor(0.2935))\n",
      "Input Sample: tensor([-0.7888,  0.1581,  0.0567])\n",
      "Target Sample: tensor(0.2935)\n",
      "Batch Input: tensor([[-1.0782,  1.8044,  1.1951],\n",
      "        [ 0.1622, -1.0616,  0.8330]])\n",
      "Batch Target: tensor([0.2080, 0.6130])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# å‡è®¾æˆ‘ä»¬æœ‰ 10 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰ 3 ä¸ªç‰¹å¾\n",
    "x_train = torch.randn(10, 3)  # è¾“å…¥æ•°æ®ï¼š10 x 3 å¼ é‡\n",
    "y_train = torch.randn(10)  # ç›®æ ‡æ•°æ®ï¼š10 ä¸ªæ ‡ç­¾\n",
    "print(\"x_train\", x_train)\n",
    "print(\"y_train\", y_train)\n",
    "# åˆ›å»ºæ•°æ®é›†\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# é€šè¿‡ç´¢å¼•è·å–ç¬¬ 0 ä¸ªæ ·æœ¬\n",
    "input_sample, target_sample = dataset[0]  # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„è¾“å…¥å’Œç›®æ ‡\n",
    "print(\"dataset[0]\", dataset[0])\n",
    "\n",
    "print(\"Input Sample:\", input_sample)\n",
    "print(\"Target Sample:\", target_sample)\n",
    "\n",
    "# åˆ›å»º DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®\n",
    "batch_input, batch_target = next(iter(dataloader))\n",
    "\n",
    "print(\"Batch Input:\", batch_input)\n",
    "print(\"Batch Target:\", batch_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111ceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (tensor(-0.5000), tensor(7.7000))\n",
      "dataloader <torch.utils.data.dataloader.DataLoader object at 0x000001D3A092ECD0>\n",
      "epoches:1,loss:2718.64697265625\n",
      "epoches:10,loss:255.8895721435547\n",
      "epoches:20,loss:59.144622802734375\n",
      "epoches:30,loss:44.492549896240234\n",
      "epoches:40,loss:44.02617645263672\n",
      "epoches:50,loss:43.70643615722656\n",
      "epoches:60,loss:43.760047912597656\n",
      "epoches:70,loss:42.99140548706055\n",
      "epoches:80,loss:43.762786865234375\n",
      "epoches:90,loss:43.896663665771484\n",
      "epoches:100,loss:43.84816360473633\n",
      "epoches:110,loss:43.033233642578125\n",
      "epoches:120,loss:44.052734375\n",
      "epoches:130,loss:44.312232971191406\n",
      "epoches:140,loss:43.637306213378906\n",
      "epoches:150,loss:43.80904769897461\n",
      "epoches:160,loss:43.3356819152832\n",
      "epoches:170,loss:43.83928298950195\n",
      "epoches:180,loss:43.7611083984375\n",
      "epoches:190,loss:43.84056854248047\n",
      "epoches:200,loss:43.92680740356445\n",
      "epoches:210,loss:43.922142028808594\n",
      "epoches:220,loss:43.750328063964844\n",
      "epoches:230,loss:42.979148864746094\n",
      "epoches:240,loss:43.26317596435547\n",
      "epoches:250,loss:43.57377624511719\n",
      "epoches:260,loss:43.662418365478516\n",
      "epoches:270,loss:43.03649139404297\n",
      "epoches:280,loss:43.65403747558594\n",
      "epoches:290,loss:43.08039093017578\n",
      "epoches:300,loss:43.267799377441406\n",
      "epoches:310,loss:43.13279342651367\n",
      "epoches:320,loss:43.77991485595703\n",
      "epoches:330,loss:43.69477844238281\n",
      "epoches:340,loss:44.03837966918945\n",
      "epoches:350,loss:43.156341552734375\n",
      "epoches:360,loss:43.90250015258789\n",
      "epoches:370,loss:43.85957717895508\n",
      "epoches:380,loss:43.89811706542969\n",
      "epoches:390,loss:43.81150817871094\n",
      "epoches:400,loss:43.51162338256836\n",
      "epoches:410,loss:44.17859649658203\n",
      "epoches:420,loss:43.89166259765625\n",
      "epoches:430,loss:44.065242767333984\n",
      "epoches:440,loss:44.056846618652344\n",
      "epoches:450,loss:43.938987731933594\n",
      "epoches:460,loss:43.79676055908203\n",
      "epoches:470,loss:43.48032760620117\n",
      "epoches:480,loss:43.88581085205078\n",
      "epoches:490,loss:43.44432067871094\n",
      "epoches:500,loss:43.69566345214844\n"
     ]
    }
   ],
   "source": [
    "\"\"\"æ•°æ®é›†åŠ è½½\"\"\"\n",
    "\"\"\"01\n",
    "PyTorch çº¿æ€§å›å½’å®ç°\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "# ataloader å¹¶ä¸å­˜å…·ä½“æ•°æ®ï¼Œåªå­˜â€œç´¢å¼•çš„ç»„åˆâ€ã€‚\n",
    "# æ•°æ®æ˜¯åœ¨ iteration æ—¶ä¸´æ—¶ä» dataset ä¸­å–å‡ºæ¥çš„ã€‚\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "print(\"dataset\", dataset[0])\n",
    "print(\"dataloader\", dataloader)\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "model = LinearModel()\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 4.å¼€å§‹è¿­ä»£\n",
    "epoches = 500\n",
    "for n in range(1, epoches + 1):\n",
    "    epoch_loss = 0\n",
    "    # ä»¥å‰éƒ½æ˜¯æ‰€æœ‰æ•°æ®ä¸€å—è®­ç»ƒï¼Œç°åœ¨æ˜¯æŒ‰ç…§æ‰¹æ¬¡è¿›è¡Œè®­ç»ƒ\n",
    "    # DataLoader å†…éƒ¨ç¡®å®ä¿å­˜ç´¢å¼•\n",
    "    # ä½†æœ€ç»ˆç»™ä½ çš„ batch_xã€batch_y å·²ç»æ˜¯â€œæ•°æ®æœ¬ä½“â€ï¼Œè€Œä¸æ˜¯ç´¢å¼•\n",
    "    # ä½ çœ‹åˆ°çš„ batch å·²ç»æ˜¯ä» dataset é‡Œâ€œå–å‡ºæ¥çš„ç»“æœâ€ï¼Œä¸æ˜¯è¦ä½ å†æ ¹æ®ç´¢å¼•å–ã€‚\n",
    "    for batch_x, batch_y in dataloader:\n",
    "\n",
    "        # ç°åœ¨x_train ç›¸å½“äº10ä¸ªæ ·æœ¬ï¼Œä½†æ˜¯ç°åœ¨ç»´åº¦ï¼Œæ·»åŠ ä¸€ä¸ªç»´åº¦\n",
    "        # 10x1   å˜æˆæ ·æœ¬ x ç»´åº¦å½¢å¼\n",
    "        y_prd = model(batch_x.unsqueeze(1))\n",
    "        # è®¡ç®—æŸå¤±\n",
    "        # y_prdåœ¨å‰é¢ï¼Œy_true æ˜¯åé¢\n",
    "        batch_loss = criterion(y_prd.squeeze(1), batch_y)\n",
    "        # æ¢¯åº¦æ›´æ–°\n",
    "        # æ¸…ç©ºä¹‹å‰å­˜å‚¨åœ¨ä¼˜åŒ–å™¨ä¸­çš„æ¢¯åº¦\n",
    "        optimizer.zero_grad()\n",
    "        # æŸå¤±å‡½æ•°å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦\n",
    "        batch_loss.backward()\n",
    "        # æ ¹æ®ä¼˜åŒ–ç®—æ³•æ›´æ–°å‚æ•°\n",
    "        optimizer.step()\n",
    "        # è®¡ç®—ä¸€ä¸‹epochçš„æŸå¤±\n",
    "        epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "        # 5ã€æ˜¾ç¤ºé¢‘ç‡è®¾ç½®\n",
    "\n",
    "    # è®¡ç®—ä¸€ä¸‹epochçš„å¹³å‡æŸå¤±\n",
    "    avg_loss = epoch_loss / (len(dataloader))\n",
    "    # ä¸å…ˆç”»å›¾\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoches:{n},loss:{avg_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad26bb",
   "metadata": {},
   "source": [
    "![1764062784660](image/test/1764062784660.png)\n",
    "| ä¿å­˜æ–¹å¼ | ä¿å­˜ç»“æ„ | ä¿å­˜å‚æ•° | åŠ è½½æ˜¯å¦éœ€è¦è‡ªå·±é‡æ–°å®šä¹‰ç»“æ„ |\n",
    "| ------------------ | ---- | ---- | -------------------- |\n",
    "| model.state_dict() | âŒ | âœ” | âœ” å¿…é¡»é‡æ–°å®šä¹‰ LinearModel |\n",
    "| torch.save(model) | âœ” | âœ” | âŒ ä¸éœ€è¦é‡æ–°å®šä¹‰ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss = 2677.47900390625\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[5.0291]])), ('layers.bias', tensor([3.1386]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 10] loss = 249.24624633789062\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[30.1898]])), ('layers.bias', tensor([16.6852]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 20] loss = 58.094093322753906\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[36.7762]])), ('layers.bias', tensor([21.8906]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 30] loss = 45.47926712036133\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.1232]])), ('layers.bias', tensor([23.6681]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 40] loss = 43.82026290893555\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3506]])), ('layers.bias', tensor([24.2816]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 50] loss = 43.29369354248047\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4064]])), ('layers.bias', tensor([24.4880]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 60] loss = 44.007972717285156\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4351]])), ('layers.bias', tensor([24.5394]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 70] loss = 43.47446823120117\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4223]])), ('layers.bias', tensor([24.5670]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 80] loss = 44.22679901123047\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4452]])), ('layers.bias', tensor([24.5882]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 90] loss = 43.84455108642578\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4184]])), ('layers.bias', tensor([24.6236]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 100] loss = 43.93196487426758\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4409]])), ('layers.bias', tensor([24.6288]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 110] loss = 44.051605224609375\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4076]])), ('layers.bias', tensor([24.5919]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 120] loss = 43.681583404541016\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4259]])), ('layers.bias', tensor([24.6118]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 130] loss = 43.510009765625\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4094]])), ('layers.bias', tensor([24.5993]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 140] loss = 43.962425231933594\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3993]])), ('layers.bias', tensor([24.6051]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 150] loss = 44.36124038696289\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4491]])), ('layers.bias', tensor([24.5894]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 160] loss = 43.45630645751953\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4269]])), ('layers.bias', tensor([24.6094]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 170] loss = 43.816627502441406\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3945]])), ('layers.bias', tensor([24.6114]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 180] loss = 44.2977180480957\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4222]])), ('layers.bias', tensor([24.5826]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 190] loss = 43.9677734375\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4174]])), ('layers.bias', tensor([24.5916]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 200] loss = 43.675376892089844\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4032]])), ('layers.bias', tensor([24.5874]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 210] loss = 43.557987213134766\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3835]])), ('layers.bias', tensor([24.6146]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 220] loss = 43.901432037353516\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4381]])), ('layers.bias', tensor([24.5942]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 230] loss = 43.984134674072266\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4524]])), ('layers.bias', tensor([24.5945]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 240] loss = 43.38941192626953\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4145]])), ('layers.bias', tensor([24.5975]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 250] loss = 43.611968994140625\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4391]])), ('layers.bias', tensor([24.5898]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 260] loss = 43.70148468017578\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3956]])), ('layers.bias', tensor([24.5813]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 270] loss = 43.638179779052734\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3761]])), ('layers.bias', tensor([24.6151]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 280] loss = 43.88349151611328\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4057]])), ('layers.bias', tensor([24.6175]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 290] loss = 43.595680236816406\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4182]])), ('layers.bias', tensor([24.6219]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 300] loss = 43.692867279052734\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4164]])), ('layers.bias', tensor([24.6280]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 310] loss = 44.17002487182617\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3416]])), ('layers.bias', tensor([24.6199]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 320] loss = 43.22658157348633\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3575]])), ('layers.bias', tensor([24.6353]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 330] loss = 43.69550704956055\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3636]])), ('layers.bias', tensor([24.6148]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 340] loss = 43.585166931152344\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4061]])), ('layers.bias', tensor([24.6148]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 350] loss = 43.993099212646484\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.3758]])), ('layers.bias', tensor([24.6247]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 360] loss = 44.00916290283203\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4194]])), ('layers.bias', tensor([24.6144]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 370] loss = 43.88774108886719\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4279]])), ('layers.bias', tensor([24.6106]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 380] loss = 43.736480712890625\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4256]])), ('layers.bias', tensor([24.5955]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 390] loss = 44.46240997314453\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4460]])), ('layers.bias', tensor([24.6108]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 400] loss = 43.71331024169922\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4328]])), ('layers.bias', tensor([24.6274]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 410] loss = 44.090293884277344\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4318]])), ('layers.bias', tensor([24.6225]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 420] loss = 44.22901916503906\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4447]])), ('layers.bias', tensor([24.5947]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 430] loss = 43.12236022949219\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4292]])), ('layers.bias', tensor([24.6299]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 440] loss = 43.407833099365234\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4213]])), ('layers.bias', tensor([24.6234]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 450] loss = 43.409645080566406\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4580]])), ('layers.bias', tensor([24.6050]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 460] loss = 43.636146545410156\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4189]])), ('layers.bias', tensor([24.5953]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 470] loss = 43.51831817626953\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4421]])), ('layers.bias', tensor([24.6093]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 480] loss = 43.857078552246094\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4056]])), ('layers.bias', tensor([24.6225]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 490] loss = 43.99017333984375\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4287]])), ('layers.bias', tensor([24.6155]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "[epoch 500] loss = 43.43022918701172\n",
      "ã€state_dict å­˜å‚¨å†…å®¹ã€‘\n",
      "OrderedDict([('layers.weight', tensor([[38.4090]])), ('layers.bias', tensor([24.6141]))])\n",
      "ã€entire_model ç±»å®ä¾‹ã€‘ LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"æ¨¡å‹ä¿å­˜æ–¹å¼1\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. åŸå§‹æ•£ç‚¹æ•°æ®\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®ï¼ˆ10 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å« x, yï¼‰\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œæ–¹ä¾¿åˆ‡ç‰‡å¤„ç†\n",
    "data = np.array(data)\n",
    "\n",
    "# åˆ†ç¦»è‡ªå˜é‡ x å’Œ å› å˜é‡ y\n",
    "x_data = data[:, 0]  # shape (10,)\n",
    "y_data = data[:, 1]  # shape (10,)\n",
    "\n",
    "# è½¬ä¸º tensorï¼Œå¹¶è®¾ç½®ä¸º float32ï¼ˆPyTorch é»˜è®¤å¿…é¡» float32ï¼‰\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Dataset ä¸ Dataloader\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# å°† (x_train, y_train) å°è£…ä¸ºä¸€ä¸ªå¯ç´¢å¼•çš„æ•°æ®é›†\n",
    "# dataset[i] ä¼šè¿”å› (x_train[i], y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# DataLoaderï¼šå¯¹ dataset è¿›è¡Œâ€œæ‰¹æ¬¡(batch)åŒ–â€å¤„ç†\n",
    "# batch_size=2 â†’ æ¯æ¬¡è¿­ä»£æå– 2 æ¡æ•°æ®\n",
    "# shuffle=True â†’ ä¼šåœ¨æ¯ä¸ª epoch å¼€å¤´æ‰“ä¹±ç´¢å¼•é¡ºåº\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. å®šä¹‰æ¨¡å‹\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# æŸå¤±å‡½æ•°ï¼šMSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼šy = wx + b\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # çº¿æ€§å±‚ Linear(è¾“å…¥ç»´åº¦=1, è¾“å‡ºç»´åº¦=1)\n",
    "        # æƒé‡çŸ©é˜µ (1,1) + åç½® (1,)\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = LinearModel()\n",
    "\n",
    "# ä¼˜åŒ–å™¨ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "# model.parameters() â†’ è¿”å› w å’Œ b ä¸¤ä¸ªå¯è®­ç»ƒå‚æ•°\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. å¼€å§‹è¿­ä»£è®­ç»ƒ\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "epoches = 500\n",
    "for n in range(1, epoches + 1):\n",
    "\n",
    "    epoch_loss = 0  # ç”¨äºè®°å½•æ¯ä¸ª epoch çš„æ€»æŸå¤±\n",
    "\n",
    "    # ä½¿ç”¨ DataLoader é€ batch è®­ç»ƒ\n",
    "    for batch_x, batch_y in dataloader:\n",
    "\n",
    "        # batch_x shape: (batch, )\n",
    "        # Linear å±‚è¦æ±‚è¾“å…¥ shape: (batch, 1)\n",
    "        y_prd = model(batch_x.unsqueeze(1))  # å¢åŠ  1 ä¸ªç»´åº¦ â†’ (batch, 1)\n",
    "\n",
    "        # è®¡ç®— batch çš„æŸå¤±\n",
    "        batch_loss = criterion(y_prd.squeeze(1), batch_y)\n",
    "\n",
    "        # æ¸…ç©ºæ¢¯åº¦ç¼“å­˜\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # æ›´æ–°å‚æ•°ï¼šw -= lr * grad_w, b -= lr * grad_b\n",
    "        optimizer.step()\n",
    "\n",
    "        # ç´¯åŠ  batch çš„æŸå¤±\n",
    "        epoch_loss += batch_loss\n",
    "\n",
    "    # è®¡ç®—å½“å‰ epoch çš„å¹³å‡æŸå¤±\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "\n",
    "    # æ‰“å°ä¿¡æ¯ + ä¿å­˜æ¨¡å‹\n",
    "    if n % 10 == 0 or n == 1:\n",
    "\n",
    "        print(f\"[epoch {n}] loss = {avg_loss}\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # æ–¹å¼ 1ï¼šä¿å­˜ state_dictï¼ˆåªä¿å­˜å‚æ•°ï¼‰\n",
    "        # ------------------------------------------------------------\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "        # state_dict é‡ŒåŒ…å«æ‰€æœ‰å±‚çš„æƒé‡å’Œåç½®\n",
    "        # {'layers.weight': tensor([[w]]), 'layers.bias': tensor([b])}\n",
    "        sd_state_dict = torch.load(\"model.pth\")\n",
    "        print(\"ã€state_dict å­˜å‚¨å†…å®¹ã€‘\")\n",
    "        print(sd_state_dict)  # åªä¿å­˜å‚æ•°ï¼Œä¸ä¿å­˜æ¨¡å‹ç»“æ„ï¼ˆç±»å®šä¹‰ï¼‰\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # æ–¹å¼ 2ï¼šä¿å­˜æ•´ä¸ªæ¨¡å‹å¯¹è±¡ï¼ˆåŒ…å«ç»“æ„ + å‚æ•°ï¼‰\n",
    "        # ------------------------------------------------------------\n",
    "        torch.save(model, \"entire_model.pth\")\n",
    "\n",
    "        # åŠ è½½ entire_model.pth ä¼šæ¢å¤ä¸€ä¸ªå®Œæ•´æ¨¡å‹å¯¹è±¡\n",
    "        # ä½†å‰æï¼šä½ å¿…é¡»åœ¨å½“å‰æ–‡ä»¶ä¸­æ‹¥æœ‰ LinearModel ç±»å®šä¹‰\n",
    "        sd_entire_model = torch.load(\"entire_model.pth\",weights_only=False)\n",
    "        print(\"ã€entire_model ç±»å®ä¾‹ã€‘\", sd_entire_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15a840",
   "metadata": {},
   "source": [
    "![1764069338028](image/test/1764069338028.png)\n",
    "![1764069351078](image/test/1764069351078.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"æ¨¡å‹åŠ è½½æ–¹å¼1\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# è¯„ä¼°æ¨¡å‹\n",
    "# è¯„ä¼°æ¨¡å‹ä¸€å®šè¦åŠ ä¸‹é¢è¿™å¥è¯\n",
    "model.eval()\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor([[1.8]], dtype=torch.float32)\n",
    "# æ·»åŠ ä¸Šä¸‹æ–‡ä¸éœ€è¦è®¡ç®—æ¢¯åº¦\n",
    "with torch.no_grad():\n",
    "    y_pre = model(x_test)\n",
    "print(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[93.7503]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"æ¨¡å‹åŠ è½½æ–¹å¼2\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "\n",
    "# ç¬¬2ç§æ–¹å¼\n",
    "entire_model = torch.load(\"entire_model.pth\", weights_only=False)\n",
    "# è¯„ä¼°æ¨¡å‹\n",
    "# è¯„ä¼°æ¨¡å‹ä¸€å®šè¦åŠ ä¸‹é¢è¿™å¥è¯\n",
    "entire_model.eval()\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor([[1.8]], dtype=torch.float32)\n",
    "# æ·»åŠ ä¸Šä¸‹æ–‡ä¸éœ€è¦è®¡ç®—æ¢¯åº¦\n",
    "with torch.no_grad():\n",
    "    y_pre = entire_model(x_test)\n",
    "print(y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc433f72",
   "metadata": {},
   "source": [
    "![1764082125394](image/test/1764082125394.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (layers): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0554]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PyTorchç›´æ¥è¾“å‡ºæ‰“å°ç½‘ç»œç»“æ„\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "        #self.layers2 = nn.Linear(3, 2)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        #x = self.layers2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "# æ‰“å°æ–¹å¼\n",
    "print(model)\n",
    "\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor(\n",
    "    [[1.8]],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "model(x_test)  # PyTorch è‡ªåŠ¨è¿”å›çš„å¼ é‡ç»“æœã€‚å¹¶è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88321d17",
   "metadata": {},
   "source": [
    "![1764123303522](image/test/1764123303522.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]               2\n",
      "            Linear-2                    [-1, 2]               4\n",
      "================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9068, -0.2576]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PyTorché€šè¿‡summayæŸ¥çœ‹æ¨¡å‹ç»“æ„\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "        self.layers2 = nn.Linear(1, 2)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.layers2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "\n",
    "\n",
    "# é»˜è®¤æ˜¯GPUå¦‚æœæ˜¯cpuæœ€å¥½æŒ‡å®šä¸€ä¸‹\n",
    "# å¦‚æœå®‰è£…äº†gpuç‰ˆçš„pytorch å¦‚æœä¸æŒ‡å®šå¯èƒ½ä¼šæŠ¥é”™\n",
    "# summary() çš„å¸¸è§è¾“å‡ºåŒ…æ‹¬ï¼š\n",
    "# Layer (type)ï¼šæ˜¾ç¤ºæ¯ä¸ªç½‘ç»œå±‚çš„ç±»å‹ï¼ˆä¾‹å¦‚ Linearã€Conv2d ç­‰ï¼‰ã€‚\n",
    "# Output Shapeï¼šæ˜¾ç¤ºæ¯ä¸ªå±‚çš„è¾“å‡ºå½¢çŠ¶ï¼ˆä¾‹å¦‚ (10, 1)ï¼‰ã€‚  å¦‚æœæ˜¯-1åˆ™è¡¨ç¤ºè¯¥ç»´åº¦å¤§å°ä¸å›ºå®š\n",
    "# ï¼ï¼ï¼ï¼ï¼è¿™é‡Œä¸€å®šè¦ææ¸…æ¥šOutput Shapeè¯´æ˜çš„æ˜¯è¾“å‡ºtesnerçš„å½¢çŠ¶\n",
    "# nn.Linear(1, 1)è¡¨ç¤ºçš„æ˜¯è¾“å…¥ç‰¹å¾æ˜¯1 è¾“å‡ºç‰¹å¾ä¹Ÿæ˜¯1\n",
    "# Param #ï¼šæ˜¾ç¤ºæ¯ä¸ªå±‚çš„å‚æ•°æ•°é‡ã€‚\n",
    "# Total paramsï¼šæ˜¾ç¤ºæ¨¡å‹çš„æ€»å‚æ•°æ•°é‡ã€‚\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1,),\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor(\n",
    "    [[1.8]],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe759a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6073, 1.1507]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorché€šè¿‡NetronæŸ¥çœ‹æ¨¡å‹ç»“æ„\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®é›†ï¼ŒåŒ…å« 10 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ä¸€ä¸ªè¾“å…¥ç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡å€¼\n",
    "data = [\n",
    "    [-0.5, 7.7],  # æ ·æœ¬ 1ï¼šè¾“å…¥ç‰¹å¾ -0.5ï¼Œç›®æ ‡å€¼ 7.7\n",
    "    [1.8, 98.5],  # æ ·æœ¬ 2ï¼šè¾“å…¥ç‰¹å¾ 1.8ï¼Œç›®æ ‡å€¼ 98.5\n",
    "    [0.9, 57.8],  # æ ·æœ¬ 3ï¼šè¾“å…¥ç‰¹å¾ 0.9ï¼Œç›®æ ‡å€¼ 57.8\n",
    "    [0.4, 39.2],  # æ ·æœ¬ 4ï¼šè¾“å…¥ç‰¹å¾ 0.4ï¼Œç›®æ ‡å€¼ 39.2\n",
    "    [-1.4, -15.7],  # æ ·æœ¬ 5ï¼šè¾“å…¥ç‰¹å¾ -1.4ï¼Œç›®æ ‡å€¼ -15.7\n",
    "    [-1.4, -37.3],  # æ ·æœ¬ 6ï¼šè¾“å…¥ç‰¹å¾ -1.4ï¼Œç›®æ ‡å€¼ -37.3\n",
    "    [-1.8, -49.1],  # æ ·æœ¬ 7ï¼šè¾“å…¥ç‰¹å¾ -1.8ï¼Œç›®æ ‡å€¼ -49.1\n",
    "    [1.5, 75.6],  # æ ·æœ¬ 8ï¼šè¾“å…¥ç‰¹å¾ 1.5ï¼Œç›®æ ‡å€¼ 75.6\n",
    "    [0.4, 34.0],  # æ ·æœ¬ 9ï¼šè¾“å…¥ç‰¹å¾ 0.4ï¼Œç›®æ ‡å€¼ 34.0\n",
    "    [0.8, 62.3],  # æ ·æœ¬ 10ï¼šè¾“å…¥ç‰¹å¾ 0.8ï¼Œç›®æ ‡å€¼ 62.3\n",
    "]\n",
    "\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„ï¼ˆç”¨äºæ–¹ä¾¿è¿›è¡Œæ•°æ®åˆ‡ç‰‡ï¼‰\n",
    "data = np.array(data)\n",
    "\n",
    "# æå–è¾“å…¥ç‰¹å¾ x_data å’Œç›®æ ‡å€¼ y_data\n",
    "x_data = data[:, 0]  # è·å–æ‰€æœ‰æ ·æœ¬çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºè¾“å…¥ç‰¹å¾\n",
    "y_data = data[:, 1]  # è·å–æ‰€æœ‰æ ·æœ¬çš„ç¬¬äºŒä¸ªå…ƒç´ ä½œä¸ºç›®æ ‡å€¼\n",
    "\n",
    "# å°†è¾“å…¥ç‰¹å¾å’Œç›®æ ‡å€¼è½¬åŒ–æˆ PyTorch Tensorï¼ˆæ•°æ®ç±»å‹ä¸º float32ï¼‰\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)  # è½¬æ¢ x_data ä¸º Tensor\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)  # è½¬æ¢ y_data ä¸º Tensor\n",
    "\n",
    "# æ‰“å° x_train çš„å†…å®¹ï¼Œä»¥éªŒè¯æ•°æ®è½¬æ¢æ˜¯å¦æˆåŠŸ\n",
    "print(x_train)\n",
    "\n",
    "# 2. æ•°æ®åŠ è½½ï¼šä½¿ç”¨ TensorDataset å’Œ DataLoader åŠ è½½æ•°æ®\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡ï¼Œå°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤Ÿé€šè¿‡ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i], y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# DataLoader ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# æ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½å¤šå°‘ä¸ªæ•°æ®\n",
    "# shuffle è¡¨ç¤ºæ˜¯å¦æ‰“ä¹±æ•°æ®\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True\n",
    ")  # è®¾ç½® batch_size=2ï¼Œä¸” shuffle=True\n",
    "\n",
    "# 3. å®šä¹‰å‰å‘æ¨¡å‹ï¼ˆå³çº¿æ€§å›å½’æ¨¡å‹ï¼‰\n",
    "import torch.nn as nn  # å¯¼å…¥ PyTorch çš„ç¥ç»ç½‘ç»œæ¨¡å—\n",
    "\n",
    "# å®šä¹‰æŸå¤±å‡½æ•°ï¼Œä½¿ç”¨å‡æ–¹è¯¯å·® (MSE) æŸå¤±ï¼Œé€‚ç”¨äºå›å½’é—®é¢˜\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4ï¼šæœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„ï¼Œé€šè¿‡ç»§æ‰¿ nn.Module å®šä¹‰è‡ªå·±çš„æ¨¡å‹\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–æ–¹æ³•ï¼šå®šä¹‰æ¨¡å‹ä¸­çš„å„ä¸ªå±‚\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()  # è°ƒç”¨çˆ¶ç±» nn.Module çš„åˆå§‹åŒ–æ–¹æ³•\n",
    "        # å®šä¹‰ä¸¤ä¸ªçº¿æ€§å±‚\n",
    "        self.layers = nn.Linear(1, 1)  # ç¬¬ä¸€å±‚ï¼šè¾“å…¥ 1 ä¸ªç‰¹å¾ï¼Œè¾“å‡º 1 ä¸ªç‰¹å¾\n",
    "        self.layers2 = nn.Linear(\n",
    "            1, 2\n",
    "        )  # ç¬¬äºŒå±‚ï¼šè¾“å…¥ 1 ä¸ªç‰¹å¾ï¼Œè¾“å‡º 2 ä¸ªç‰¹å¾ï¼ˆä¸ºäº†æ¼”ç¤ºå¯ä»¥ä¿®æ”¹ï¼‰\n",
    "\n",
    "    # å‰å‘ä¼ æ’­æ–¹æ³•ï¼šå®šä¹‰æ•°æ®å¦‚ä½•é€šè¿‡ç½‘ç»œè¿›è¡Œå‰å‘ä¼ é€’\n",
    "    def forward(self, x):\n",
    "        # æ•°æ®ä¾æ¬¡é€šè¿‡ä¸¤å±‚\n",
    "        x = self.layers(x)  # ç»è¿‡ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢\n",
    "        x = self.layers2(x)  # ç»è¿‡ç¬¬äºŒå±‚çº¿æ€§å˜æ¢\n",
    "        return x  # è¿”å›è¾“å‡ºç»“æœ\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹å¯¹è±¡\n",
    "model = LinearModel()\n",
    "\n",
    "# 4. æ¨¡å‹ä¿å­˜ï¼šå°†æ¨¡å‹çš„å‚æ•°ä¿å­˜åˆ°æ–‡ä»¶ä¸­\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ï¼šä¿å­˜æ¨¡å‹å‚æ•°ï¼ˆstate_dictï¼‰è€Œä¸ä¿å­˜æ¨¡å‹ç»“æ„\n",
    "torch.save(model.state_dict(), \"model.pth\")  # ä¿å­˜æ¨¡å‹çš„çŠ¶æ€å­—å…¸ï¼ˆåªåŒ…å«æƒé‡å’Œåç½®ï¼‰\n",
    "\n",
    "# å®šä¹‰æµ‹è¯•æ•°æ®\n",
    "x_test = torch.tensor([[1.8]], dtype=torch.float32)  # è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œç‰¹å¾ä¸º 1.8\n",
    "# æ¨¡å‹æ¨ç†ï¼šé€šè¿‡æ¨¡å‹è®¡ç®—è¾“å‡º\n",
    "model(x_test)\n",
    "\n",
    "# 5. æŸ¥çœ‹æ¨¡å‹ç»“æ„\n",
    "# Netron æ˜¯ä¸€ä¸ªå¯è§†åŒ–å·¥å…·ï¼Œç”¨äºæŸ¥çœ‹ PyTorch æ¨¡å‹ç»“æ„\n",
    "# å¯ä»¥é€šè¿‡ Netron åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æ¨¡å‹æ¶æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5540f",
   "metadata": {},
   "source": [
    "![1764124553653](image/test/1764124553653.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5781, 0.4188]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PyTorché€šè¿‡NetronæŸ¥çœ‹æ¨¡å‹ç»“æ„-å¢åŠ æ¨¡å‹è¿çº¿\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "        self.layers2 = nn.Linear(1, 2)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.layers2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "# step1,å…ˆè½¬åŒ–ä¸ºè„šæœ¬æ¨¡å‹\n",
    "script_model = torch.jit.script(model)\n",
    "# step2ä¿å­˜ä¸ºæ–‡ä»¶\n",
    "torch.jit.save(script_model, \"script_model.pth\")\n",
    "\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor([[1.8]], dtype=torch.float32)\n",
    "model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f98f0",
   "metadata": {},
   "source": [
    "![1764124720089](image/test/1764124720089.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cc077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `LinearModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `LinearModel([...]` with `torch.export.export(..., strict=False)`... âœ…\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... âœ…\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... âœ…\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3230,  0.5071]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PyTorché€šè¿‡NetronæŸ¥çœ‹æ¨¡å‹ç»“æ„-å¢åŠ æ¨¡å‹è¿çº¿2\"\"\"\n",
    "\n",
    "\"\"\"01\n",
    "PyTorch çº¿æ€§å›å½’å®ç°\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "data = np.array(data)\n",
    "# æå– x_data å’Œ y_data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_data å’Œy_data è½¬åŒ–æˆtensor\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "# å¯¼å…¥ç±»åº“ Dataloader TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# TensorDataset ä¸»è¦ç”¨äºå°è£…å¼ é‡,å°†è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆä¸€ä¸ªæ•°æ®é›†\n",
    "# è¿”å›å€¼èƒ½å¤ŸæŒ‰ç…§ç´¢å¼•è·å¾—æ•°æ®å’Œæ ‡ç­¾ï¼Œä¾‹å¦‚(x_train[i],y_train[i])\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "# DataLoader,æ•°æ®åŠ è½½å™¨ç»“åˆäº†æ•°æ®é›†å’Œé‡‡æ ·å™¨ï¼Œå¹¶ä¸ºç»™å®šçš„æ•°æ®é›†æä¾›å¯è¿­ä»£æ€§\n",
    "# è¿”å›å€¼dataloaderæ˜¯å¯è¿­ä»£çš„å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£ç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œç”±è¾“å…¥å¼ é‡å’Œç›®æ ‡å¼ é‡ç»„æˆçš„å…ƒç»„ç»„æˆ\n",
    "# batch_size è¡¨ç¤ºä¸€æ¬¡åŠ è½½åˆ°å†…å­˜å¤šå°‘ä¸ªæ•°æ®ï¼Œ\n",
    "# shuffle å°±è¡¨ç¤ºæ‰“ä¹±\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# å¦‚æœbatch_size=3 é•¿åº¦ä¸º10 æ€ä¹ˆåˆ’åˆ†ä¸€ä¸‹ï¼Ÿ 111 111 111 1\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰æŸå¤±\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4\n",
    "# æœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„\n",
    "# ç›´æ¥é‡å†™ç»§æ‰¿nn.Module\n",
    "class LinearModel(nn.Module):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # å®šä¹‰ä¸€ä¸ªnn.ModuleList\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "        self.layers2 = nn.Linear(1, 2)\n",
    "\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.layers2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸‹æ¨¡å‹ï¼Œè¿”å›æ¨¡å‹å¯¹è±¡\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€ç§æ–¹å¼ åªä¿å­˜çš„æ¨¡å‹å‚æ•°çš„æ–¹å¼ï¼š\n",
    "# åŠ è½½æ¨¡å‹éœ€è¦3æ­¥éª¤ï¼š\n",
    "# æ­¥éª¤1ï¼šéœ€è¦æ¨¡å‹ç»“æ„(ä¿å­˜æ—¶æ­å»ºçš„æ¨¡å‹)\n",
    "# æ­¥éª¤2ï¼šä½¿ç”¨torch.load(\"model.pth\")åŠ è½½æ¨¡å‹å‚æ•°\n",
    "# æ­¥éª¤2ï¼š:å®ä¾‹åŒ–æ¨¡å‹ï¼ˆmodelï¼‰ä½¿ç”¨model.load_state_dict(torch.load(\"model.pth\"))å°†modelå’Œå‚æ•°ç»“åˆèµ·æ¥ï¼Œ\n",
    "model = LinearModel()\n",
    "# æ–¹æ³•2 è½¬åŒ–ä¸ºONNXæ¨¡å‹ï¼Œå¦‚æœä¸èƒ½è¿è¡Œå°±å®‰è£…onnx\n",
    "# modelæ˜¯# pytorchç½‘ç»œæ¨¡å‹\n",
    "#         args,    # éšæœºçš„æ¨¡æ‹Ÿè¾“å…¥\n",
    "#         model_path,     # å¯¼å‡ºçš„onnxæ–‡ä»¶ä½ç½®\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.rand(1, 1),\n",
    "    \"model.onnx\",\n",
    ")\n",
    "\n",
    "\n",
    "# å®šä¹‰æ•°æ®\n",
    "x_test = torch.tensor([[1.8]], dtype=torch.float32)\n",
    "model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e49087",
   "metadata": {},
   "source": [
    "![1764125067654](image/test/1764125067654.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches: 1, loss: 3010.80078125\n",
      "epoches: 10, loss: 1816.6536865234375\n",
      "epoches: 20, loss: 1048.9097900390625\n",
      "epoches: 30, loss: 616.7817993164062\n",
      "epoches: 40, loss: 372.4057312011719\n",
      "epoches: 50, loss: 233.4542236328125\n",
      "epoches: 60, loss: 153.95687866210938\n",
      "epoches: 70, loss: 108.15767669677734\n",
      "epoches: 80, loss: 81.5685806274414\n",
      "epoches: 90, loss: 66.0016860961914\n",
      "epoches: 100, loss: 56.80542755126953\n",
      "epoches: 110, loss: 51.320777893066406\n",
      "epoches: 120, loss: 48.01740264892578\n",
      "epoches: 130, loss: 46.00783157348633\n",
      "epoches: 140, loss: 44.773162841796875\n",
      "epoches: 150, loss: 44.007225036621094\n",
      "epoches: 160, loss: 43.52765655517578\n",
      "epoches: 170, loss: 43.224754333496094\n",
      "epoches: 180, loss: 43.03191375732422\n",
      "epoches: 190, loss: 42.908226013183594\n",
      "epoches: 200, loss: 42.828392028808594\n",
      "epoches: 210, loss: 42.77656555175781\n",
      "epoches: 220, loss: 42.74274444580078\n",
      "epoches: 230, loss: 42.72056579589844\n",
      "epoches: 240, loss: 42.70600128173828\n",
      "epoches: 250, loss: 42.696372985839844\n",
      "epoches: 260, loss: 42.690006256103516\n",
      "epoches: 270, loss: 42.68579864501953\n",
      "epoches: 280, loss: 42.68297576904297\n",
      "epoches: 290, loss: 42.681114196777344\n",
      "epoches: 300, loss: 42.67988204956055\n",
      "epoches: 310, loss: 42.679046630859375\n",
      "epoches: 320, loss: 42.678497314453125\n",
      "epoches: 330, loss: 42.678123474121094\n",
      "epoches: 340, loss: 42.67787551879883\n",
      "epoches: 350, loss: 42.677711486816406\n",
      "epoches: 360, loss: 42.6776123046875\n",
      "epoches: 370, loss: 42.67753219604492\n",
      "epoches: 380, loss: 42.677486419677734\n",
      "epoches: 390, loss: 42.67744827270508\n",
      "epoches: 400, loss: 42.67742156982422\n",
      "epoches: 410, loss: 42.67741012573242\n",
      "epoches: 420, loss: 42.677391052246094\n",
      "epoches: 430, loss: 42.67738723754883\n",
      "epoches: 440, loss: 42.6773796081543\n",
      "epoches: 450, loss: 42.6773796081543\n",
      "epoches: 460, loss: 42.6773796081543\n",
      "epoches: 470, loss: 42.67738723754883\n",
      "epoches: 480, loss: 42.67738723754883\n",
      "epoches: 490, loss: 42.6773681640625\n",
      "epoches: 500, loss: 42.67738342285156\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pythonä½¿ç”¨TensorboardXæŸ¥çœ‹ç½‘ç»œç»“æ„\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1.æ•£ç‚¹è¾“å…¥\n",
    "# 1ã€æ•£ç‚¹è¾“å…¥\n",
    "# å®šä¹‰è¾“å…¥æ•°æ®ï¼Œæ•°æ®æ ¼å¼ä¸ºæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªç‰¹å¾å€¼ï¼ˆxï¼‰å’Œå¯¹åº”çš„ç›®æ ‡å€¼ï¼ˆyï¼‰\n",
    "data = [\n",
    "    [-0.5, 7.7],\n",
    "    [1.8, 98.5],\n",
    "    [0.9, 57.8],\n",
    "    [0.4, 39.2],\n",
    "    [-1.4, -15.7],\n",
    "    [-1.4, -37.3],\n",
    "    [-1.8, -49.1],\n",
    "    [1.5, 75.6],\n",
    "    [0.4, 34.0],\n",
    "    [0.8, 62.3],\n",
    "]\n",
    "# å°†æ•°æ®è½¬åŒ–ä¸ºNumPyæ•°ç»„ï¼Œæ–¹ä¾¿å¤„ç†\n",
    "data = np.array(data)\n",
    "# æå–æ•°æ®ä¸­çš„ç‰¹å¾åˆ—ï¼ˆx_dataï¼‰å’Œç›®æ ‡åˆ—ï¼ˆy_dataï¼‰\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# å°†x_dataå’Œy_dataè½¬åŒ–ä¸ºPyTorchçš„tensoræ ¼å¼ï¼Œdtype=torch.float32æŒ‡å®šäº†æ•°æ®ç±»å‹\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)  # ç‰¹å¾æ•°æ®\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)  # ç›®æ ‡æ•°æ®\n",
    "\n",
    "# 2.å®šä¹‰å‰å‘æ¨¡å‹\n",
    "# PyTorchä¸­çš„æ¨¡å‹é€šå¸¸ç»§æ‰¿è‡ªnn.Moduleï¼Œè¿™é‡Œæ˜¯æ„å»ºä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹\n",
    "import torch.nn as nn\n",
    "\n",
    "# å¯¼å…¥TensorboardXä¸­çš„SummaryWriterï¼Œç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# åˆ›å»ºSummaryWriterå¯¹è±¡ï¼ŒæŒ‡å®šæ—¥å¿—æ–‡ä»¶è·¯å¾„\n",
    "writer = SummaryWriter(logdir=\"logs\")\n",
    "\n",
    "# å¯è§†åŒ–ä¸€ä¸ªç¥ç»ç½‘ç»œ\n",
    "\n",
    "\n",
    "# æ–¹æ¡ˆ4ï¼šæœ€å¸¸ç”¨çš„ç½‘ç»œç»“æ„ï¼Œå®šä¹‰ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹\n",
    "# ç»§æ‰¿è‡ªnn.Moduleç±»ï¼Œè¿™æ ·å¯ä»¥ä½¿ç”¨PyTorchæä¾›çš„æ‰€æœ‰åŠŸèƒ½ï¼Œå¦‚è‡ªåŠ¨æ±‚å¯¼\n",
    "class LinearModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        # è°ƒç”¨çˆ¶ç±»ï¼ˆnn.Moduleï¼‰çš„æ„é€ å‡½æ•°\n",
    "        super(LinearModule, self).__init__()\n",
    "        # å®šä¹‰ç½‘ç»œå±‚ï¼Œnn.Linearè¡¨ç¤ºå…¨è¿æ¥å±‚ï¼Œ1ä¸ªè¾“å…¥ç‰¹å¾ï¼Œ1ä¸ªè¾“å‡ºç‰¹å¾\n",
    "        self.layers = nn.Linear(1, 1)\n",
    "        # self.layers1 = nn.Linear(1, 1)  # å¦‚æœæœ‰ç¬¬äºŒä¸ªå±‚ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š\n",
    "\n",
    "    # å‰å‘ä¼ æ’­çš„å®šä¹‰\n",
    "    def forward(self, x):\n",
    "        # è¾“å…¥xé€šè¿‡çº¿æ€§å±‚è¿›è¡Œå˜æ¢\n",
    "        x = self.layers(x)\n",
    "        # x = self.layers1(x)  # å¦‚æœæœ‰ç¬¬äºŒä¸ªå±‚ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š\n",
    "        return x\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹å¯¹è±¡\n",
    "model = LinearModule()\n",
    "\n",
    "# 3.å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "# PyTorchä¸­æœ‰è®¸å¤šæŸå¤±å‡½æ•°ï¼Œè¿™é‡Œä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSELossï¼‰ä½œä¸ºæŸå¤±å‡½æ•°\n",
    "criterion = nn.MSELoss()\n",
    "# ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è®¾ä¸º0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 4.å¼€å§‹è¿­ä»£è®­ç»ƒ\n",
    "epoches = 500  # è®­ç»ƒçš„æ€»è½®æ•°\n",
    "\n",
    "for n in range(1, epoches + 1):\n",
    "    # 5.è·å–é¢„æµ‹å€¼\n",
    "    # x_trainçš„å½¢çŠ¶æ˜¯(10,)ï¼Œä¸ºäº†ç¬¦åˆè¾“å…¥è¦æ±‚ï¼Œé€šè¿‡unsqueezeæ·»åŠ ç»´åº¦ï¼Œä½¿å…¶æˆä¸º(10, 1)\n",
    "    # è¿™ç¬¦åˆnn.Linearå±‚çš„è¾“å…¥è¦æ±‚ï¼ˆæ‰¹æ¬¡å¤§å° Ã— è¾“å…¥ç‰¹å¾æ•°ï¼‰\n",
    "    y_hat = model(x_train.unsqueeze(1))  # å‰å‘ä¼ æ’­è·å–æ¨¡å‹é¢„æµ‹ç»“æœ\n",
    "\n",
    "    # è®¡ç®—æŸå¤±ï¼Œé¢„æµ‹å€¼y_hatå’ŒçœŸå®å€¼y_trainåšå¯¹æ¯”ï¼Œè®¡ç®—å‡æ–¹è¯¯å·®\n",
    "    loss = criterion(y_hat.squeeze(1), y_train)  # squeeze(1)å°†y_hatå˜å›ä¸€ç»´\n",
    "\n",
    "    # 6.æ¢¯åº¦æ›´æ–°\n",
    "    # æ¸…ç©ºä¹‹å‰å­˜å‚¨åœ¨ä¼˜åŒ–å™¨ä¸­çš„æ¢¯åº¦ä¿¡æ¯\n",
    "    optimizer.zero_grad()\n",
    "    # è®¡ç®—å½“å‰æŸå¤±å‡½æ•°å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦\n",
    "    loss.backward()\n",
    "    # æ ¹æ®ä¼˜åŒ–ç®—æ³•æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "    optimizer.step()\n",
    "    # 7.æ¯éš”ä¸€å®šæ¬¡æ•°æ˜¾ç¤ºå½“å‰æŸå¤±\n",
    "    # ä½¿ç”¨TensorBoardXçš„add_scalaræ–¹æ³•è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å€¼å’Œå­¦ä¹ ç‡\n",
    "    # è¿™äº›è®°å½•çš„å€¼å°†åœ¨TensorBoardä¸­æ˜¾ç¤ºï¼Œå¸®åŠ©ä½ è§‚å¯Ÿæ¨¡å‹è®­ç»ƒçš„è¿›å±•å’Œä¼˜åŒ–æ•ˆæœ\n",
    "\n",
    "    # è®°å½•æŸå¤±å€¼ï¼Œ'loss' æ˜¯åœ¨TensorBoardä¸­æ˜¾ç¤ºçš„æ ‡ç­¾åï¼Œlossæ˜¯å½“å‰çš„æŸå¤±å€¼ï¼Œnæ˜¯å½“å‰çš„è¿­ä»£æ¬¡æ•°\n",
    "    # \"loss\" æ˜¯è®°å½•åˆ°TensorBoardä¸­çš„æ ‡ç­¾ï¼ˆåç§°ï¼‰ï¼Œloss æ˜¯å½“å‰è®¡ç®—çš„æŸå¤±å€¼ï¼Œn è¡¨ç¤ºå½“å‰çš„è®­ç»ƒè½®æ¬¡\n",
    "    writer.add_scalar(\n",
    "        \"loss\",  # æ ‡ç­¾åï¼ˆåœ¨TensorBoardä¸­æ˜¾ç¤ºçš„åç§°ï¼‰\n",
    "        loss,  # å½“å‰è®­ç»ƒè½®æ¬¡è®¡ç®—çš„æŸå¤±å€¼\n",
    "        n,  # å½“å‰çš„è®­ç»ƒè½®æ¬¡ï¼Œä½œä¸ºxè½´ï¼ˆå¯ä»¥æ˜¯è¿­ä»£æ¬¡æ•°ï¼‰\n",
    "    )\n",
    "\n",
    "    # è®°å½•å½“å‰å­¦ä¹ ç‡ï¼Œ'learning_rate' æ˜¯æ˜¾ç¤ºçš„æ ‡ç­¾åï¼Œoptimizer.param_groups[0][\"lr\"] æ˜¯å½“å‰çš„å­¦ä¹ ç‡\n",
    "    # \"learning_rate\" æ˜¯è®°å½•åˆ°TensorBoardä¸­çš„æ ‡ç­¾ï¼ˆåç§°ï¼‰ï¼Œoptimizer.param_groups[0][\"lr\"] æ˜¯å½“å‰å­¦ä¹ ç‡çš„å€¼\n",
    "    # n è¡¨ç¤ºå½“å‰çš„è®­ç»ƒè½®æ¬¡ï¼Œè®°å½•å­¦ä¹ ç‡éšè®­ç»ƒè½®æ¬¡çš„å˜åŒ–\n",
    "    writer.add_scalar(\n",
    "        \"learning_rate\",  # æ ‡ç­¾åï¼ˆåœ¨TensorBoardä¸­æ˜¾ç¤ºçš„åç§°ï¼‰\n",
    "        optimizer.param_groups[0][\"lr\"],  # å½“å‰çš„å­¦ä¹ ç‡ï¼ˆé€šè¿‡ä¼˜åŒ–å™¨è·å–ï¼‰\n",
    "        n,  # å½“å‰çš„è®­ç»ƒè½®æ¬¡ï¼Œä½œä¸ºxè½´\n",
    "    )\n",
    "\n",
    "    # æ¯10æ¬¡è¾“å‡ºä¸€æ¬¡è®­ç»ƒä¿¡æ¯\n",
    "    if n % 10 == 0 or n == 1:\n",
    "        print(f\"epoches: {n}, loss: {loss}\")\n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹å‚æ•°\n",
    "        torch.save(model.state_dict(), f\"./model{n}.pth\")\n",
    "\n",
    "# 8.è®°å½•æ¨¡å‹çš„è®¡ç®—å›¾ï¼ˆå¯è§†åŒ–ç½‘ç»œç»“æ„ï¼‰\n",
    "# writer.add_graph()ä¼šå°†æ¨¡å‹ç»“æ„å†™å…¥æ—¥å¿—æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åœ¨TensorBoardä¸­æŸ¥çœ‹\n",
    "# è¿™é‡Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨writer.add_graph()å°†å½“å‰æ¨¡å‹çš„è®¡ç®—å›¾ä¿å­˜åˆ°TensorBoardçš„æ—¥å¿—ä¸­ï¼Œ\n",
    "# ä»¥ä¾¿åç»­å¯ä»¥ä½¿ç”¨TensorBoardè¿›è¡Œå¯è§†åŒ–\n",
    "\n",
    "writer.add_graph(\n",
    "    model,  # æ¨¡å‹å¯¹è±¡ï¼ŒTensorBoardä¼šæ ¹æ®è¿™ä¸ªæ¨¡å‹æ„å»ºè®¡ç®—å›¾\n",
    "    torch.rand(1),  # æ¨¡æ‹Ÿè¾“å…¥çš„å½¢çŠ¶å’Œç±»å‹ã€‚ä¸ºäº†ç”Ÿæˆè®¡ç®—å›¾ï¼Œå¿…é¡»æä¾›æ¨¡å‹æ‰€éœ€çš„è¾“å…¥æ•°æ®ã€‚\n",
    "    # è¿™é‡Œä¼ å…¥äº†ä¸€ä¸ªå½¢çŠ¶ä¸º(1,)çš„éšæœºæ•°å¼ é‡ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ï¼Œè¿™ä¸ªè¾“å…¥ä¼šæ ¹æ®å®é™…æ¨¡å‹è¿›è¡Œè‡ªåŠ¨æ¨æ–­\n",
    "    # ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ªçº¿æ€§å±‚nn.Linear(1,1)ï¼Œè¿™ä¸ªè¾“å…¥çš„ç»´åº¦åº”ä¸º(1,)ï¼Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬åŒ…å«1ä¸ªç‰¹å¾ã€‚\n",
    ")\n",
    "\n",
    "# 9.å…³é—­SummaryWriterå¯¹è±¡\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
